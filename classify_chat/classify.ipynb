{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unnecessary-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "central-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reported-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from functools import partial\n",
    "from optparse import OptionParser\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "postal-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "persistent-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "# from sklearn.utils.extmath import densityfeature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "turkish-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stock-narrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from tokenizer.ipynb\n",
      "(20000, 2)\n",
      "20000 documents - 0.837MB (training set)\n",
      "1017 documents - 0.061MB (test set)\n",
      "\n",
      "Stored 'data_train' (DataFrame)\n",
      "Stored 'X_train' (Series)\n",
      "Stored 'X_test' (Series)\n",
      "Stored 'y_train' (list)\n",
      "Stored 'y_test' (list)\n",
      "Stored 'data_train_size_mb' (float)\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 1.714275s at 0.488MB/s\n",
      "n_samples: 20000, n_features: 980\n",
      "\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 3.125427s at 0.268MB/s\n",
      "n_samples: 20000, n_features: 981\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 0.196661s at 0.311MB/s\n",
      "n_samples: 1017, n_features: 981\n",
      "\n",
      "Stored 'X_train' (csr_matrix)\n",
      "Stored 'X_test' (csr_matrix)\n",
      "Stored 'feature_names' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%run embedding.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "conditional-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interactive():\n",
    "    return not hasattr(sys.modules['__main__'], '__file__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "catholic-confirmation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Option at 0x7f5d9f52de90: --n_features>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = OptionParser()\n",
    "\n",
    "op.add_option(\"--report\",\n",
    "              action=\"store_true\", dest=\"print_report\", default=True,\n",
    "              help=\"Print a detailed classification report.\")\n",
    "\n",
    "op.add_option(\"--chi2_select\",\n",
    "              action=\"store\", type=\"int\", dest=\"select_chi2\",\n",
    "              help=\"Select some number of features using a chi-squared test\")\n",
    "\n",
    "op.add_option(\"--confusion_matrix\",\n",
    "              action=\"store_true\", dest=\"print_cm\",\n",
    "              help=\"Print the confusion matrix.\")\n",
    "\n",
    "op.add_option(\"--top10\",\n",
    "              action=\"store_true\", dest=\"print_top10\",\n",
    "              help=\"Print ten most discriminative terms per class for every classifier.\")\n",
    "\n",
    "op.add_option(\"--use_hashing\",\n",
    "              action=\"store_true\",\n",
    "              help=\"Use a hashing vectorizer.\")\n",
    "\n",
    "op.add_option(\"--n_features\",\n",
    "              action=\"store\", type=int, default=2 ** 16,\n",
    "              help=\"n_features when using the hashing vectorizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "raised-organizer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Values at 0x7f5d9f582450: {'print_report': True, 'select_chi2': None, 'print_cm': None, 'print_top10': None, 'use_hashing': None, 'n_features': 65536}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# work-around for Jupyter notebook and IPython console\n",
    "\n",
    "# opts, an object containing values for all of your options\n",
    "#     e.g. if --file takes a single string argument, then options.file will be the filename supplied by the user, \n",
    "#     or None if the user did not supply that option\n",
    "# args, the list of positional arguments leftover after parsing options\n",
    "\n",
    "argv = [] if is_interactive() else sys.argv[1:]\n",
    "(opts, args) = op.parse_args(argv)\n",
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ranging-modem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Usage: ipykernel_launcher.py [options]\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --report              Print a detailed classification report.\n",
      "  --chi2_select=SELECT_CHI2\n",
      "                        Select some number of features using a chi-squared\n",
      "                        test\n",
      "  --confusion_matrix    Print the confusion matrix.\n",
      "  --top10               Print ten most discriminative terms per class for\n",
      "                        every classifier.\n",
      "  --use_hashing         Use a hashing vectorizer.\n",
      "  --n_features=N_FEATURES\n",
      "                        n_features when using the hashing vectorizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(args) > 0:\n",
    "    op.error(\"this script takes no arguments.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(__doc__)\n",
    "op.print_help()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-campaign",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "super-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train\n",
    "%store -r X_test\n",
    "%store -r y_train\n",
    "%store -r y_test\n",
    "\n",
    "%store -r feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-karen",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stunning-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "constitutional-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(clf, X_train, y_train):\n",
    "    \n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "    \n",
    "    return train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hourly-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(clf, X_test):\n",
    "    \n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "    \n",
    "    return pred, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "jewish-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, pred):\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fiscal-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_coef(clf, opts, feature_names):\n",
    "    # TODO:\n",
    "    \n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        # print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if opts.print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            \n",
    "            #for i, label in enumerate(target_names):\n",
    "              #  top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                #print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "regional-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(opts, y_test, pred):\n",
    "    \n",
    "    if opts.print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "attempted-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(opts, y_test, pred):\n",
    "    \n",
    "    if opts.print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "false-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc(clf):\n",
    "    return str(clf).split('(')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "leading-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __benchmark(X_train, y_train, X_test, y_test, opts, feature_names, clf):\n",
    "    \n",
    "    train_time = fit(clf, X_train, y_train)\n",
    "    pred, test_time = predict(clf, X_test)\n",
    "    score = accuracy(y_test, pred)\n",
    "    clf_descr = get_desc(clf)\n",
    "\n",
    "    print_coef(clf, opts, feature_names)\n",
    "    print_report(opts, y_test, pred)\n",
    "    print_cm(opts, y_test, pred)\n",
    "    print()\n",
    "    \n",
    "    return pred, clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "necessary-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = partial(__benchmark, X_train, y_train, X_test, y_test, opts, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-march",
   "metadata": {},
   "source": [
    "## score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rising-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "continued-supervisor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(solver='sag', tol=0.01)\n",
      "train time: 0.080s\n",
      "test time:  0.001s\n",
      "accuracy:   0.925\n",
      "dimensionality: 981\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.80      0.87       313\n",
      "           1       0.92      0.98      0.95       704\n",
      "\n",
      "    accuracy                           0.93      1017\n",
      "   macro avg       0.93      0.89      0.91      1017\n",
      "weighted avg       0.93      0.93      0.92      1017\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(max_iter=50)\n",
      "train time: 0.017s\n",
      "test time:  0.001s\n",
      "accuracy:   0.918\n",
      "dimensionality: 981\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.88      0.87       313\n",
      "           1       0.95      0.94      0.94       704\n",
      "\n",
      "    accuracy                           0.92      1017\n",
      "   macro avg       0.90      0.91      0.90      1017\n",
      "weighted avg       0.92      0.92      0.92      1017\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(max_iter=50)\n",
      "train time: 0.026s\n",
      "test time:  0.001s\n",
      "accuracy:   0.942\n",
      "dimensionality: 981\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.88      0.90       313\n",
      "           1       0.95      0.97      0.96       704\n",
      "\n",
      "    accuracy                           0.94      1017\n",
      "   macro avg       0.94      0.93      0.93      1017\n",
      "weighted avg       0.94      0.94      0.94      1017\n",
      "\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(n_neighbors=10)\n",
      "train time: 0.003s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyh/anaconda3/envs/tf2.4/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:556: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.696s\n",
      "accuracy:   0.899\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.77      0.82       313\n",
      "           1       0.90      0.96      0.93       704\n",
      "\n",
      "    accuracy                           0.90      1017\n",
      "   macro avg       0.89      0.86      0.88      1017\n",
      "weighted avg       0.90      0.90      0.90      1017\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier()\n",
      "train time: 6.230s\n",
      "test time:  0.046s\n",
      "accuracy:   0.944\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.87      0.91       313\n",
      "           1       0.94      0.98      0.96       704\n",
      "\n",
      "    accuracy                           0.94      1017\n",
      "   macro avg       0.94      0.92      0.93      1017\n",
      "weighted avg       0.94      0.94      0.94      1017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(max_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(max_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "celtic-wallet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(dual=False, tol=0.001)\n",
      "train time: 0.039s\n",
      "test time:  0.001s\n",
      "accuracy:   0.945\n",
      "dimensionality: 981\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.87      0.91       313\n",
      "           1       0.95      0.98      0.96       704\n",
      "\n",
      "    accuracy                           0.94      1017\n",
      "   macro avg       0.94      0.92      0.93      1017\n",
      "weighted avg       0.94      0.94      0.94      1017\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50)\n",
      "train time: 0.020s\n",
      "test time:  0.001s\n",
      "accuracy:   0.941\n",
      "dimensionality: 981\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.84      0.90       313\n",
      "           1       0.93      0.98      0.96       704\n",
      "\n",
      "    accuracy                           0.94      1017\n",
      "   macro avg       0.95      0.91      0.93      1017\n",
      "weighted avg       0.94      0.94      0.94      1017\n",
      "\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(dual=False, penalty='l1', tol=0.001)\n",
      "train time: 0.330s\n",
      "test time:  0.001s\n",
      "accuracy:   0.938\n",
      "dimensionality: 981\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.87      0.90       313\n",
      "           1       0.94      0.97      0.96       704\n",
      "\n",
      "    accuracy                           0.94      1017\n",
      "   macro avg       0.94      0.92      0.93      1017\n",
      "weighted avg       0.94      0.94      0.94      1017\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50, penalty='l1')\n",
      "train time: 0.028s\n",
      "test time:  0.000s\n",
      "accuracy:   0.922\n",
      "dimensionality: 981\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.82      0.87       313\n",
      "           1       0.92      0.97      0.95       704\n",
      "\n",
      "    accuracy                           0.92      1017\n",
      "   macro avg       0.92      0.89      0.91      1017\n",
      "weighted avg       0.92      0.92      0.92      1017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50, penalty=penalty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "following-graham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50, penalty='elasticnet')\n",
      "train time: 0.040s\n",
      "test time:  0.001s\n",
      "accuracy:   0.939\n",
      "dimensionality: 981\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.84      0.89       313\n",
      "           1       0.93      0.98      0.96       704\n",
      "\n",
      "    accuracy                           0.94      1017\n",
      "   macro avg       0.94      0.91      0.93      1017\n",
      "weighted avg       0.94      0.94      0.94      1017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50, penalty=\"elasticnet\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "periodic-persian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid()\n",
      "train time: 0.008s\n",
      "test time:  0.001s\n",
      "accuracy:   0.857\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.73      0.76       313\n",
      "           1       0.89      0.91      0.90       704\n",
      "\n",
      "    accuracy                           0.86      1017\n",
      "   macro avg       0.84      0.82      0.83      1017\n",
      "weighted avg       0.86      0.86      0.86      1017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "respected-ballot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01)\n",
      "train time: 0.010s\n",
      "test time:  0.001s\n",
      "accuracy:   0.864\n",
      "dimensionality: 981\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.68      0.76       313\n",
      "           1       0.87      0.94      0.91       704\n",
      "\n",
      "    accuracy                           0.86      1017\n",
      "   macro avg       0.86      0.81      0.83      1017\n",
      "weighted avg       0.86      0.86      0.86      1017\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01)\n",
      "train time: 0.010s\n",
      "test time:  0.001s\n",
      "accuracy:   0.869\n",
      "dimensionality: 981\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.69      0.77       313\n",
      "           1       0.87      0.95      0.91       704\n",
      "\n",
      "    accuracy                           0.87      1017\n",
      "   macro avg       0.86      0.82      0.84      1017\n",
      "weighted avg       0.87      0.87      0.87      1017\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "ComplementNB(alpha=0.1)\n",
      "train time: 0.006s\n",
      "test time:  0.000s\n",
      "accuracy:   0.883\n",
      "dimensionality: 981\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.87      0.82       313\n",
      "           1       0.94      0.89      0.91       704\n",
      "\n",
      "    accuracy                           0.88      1017\n",
      "   macro avg       0.86      0.88      0.87      1017\n",
      "weighted avg       0.89      0.88      0.88      1017\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyh/anaconda3/envs/tf2.4/lib/python3.7/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/wangyh/anaconda3/envs/tf2.4/lib/python3.7/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/wangyh/anaconda3/envs/tf2.4/lib/python3.7/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "results.append(benchmark(ComplementNB(alpha=.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "stylish-jefferson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(dual=False, penalty='l1',\n",
      "                                                     tol=0.001))),\n",
      "                ('classification', LinearSVC())])\n",
      "train time: 0.379s\n",
      "test time:  0.001s\n",
      "accuracy:   0.948\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.88      0.91       313\n",
      "           1       0.95      0.98      0.96       704\n",
      "\n",
      "    accuracy                           0.95      1017\n",
      "   macro avg       0.95      0.93      0.94      1017\n",
      "weighted avg       0.95      0.95      0.95      1017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abandoned-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 2**5-1, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'\n",
    "\n",
    "num_round = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fatty-sailing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 981)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bigger-colleague",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 981)\n",
      "(20000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 982)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = np.expand_dims(data_train['content'].apply(len).to_numpy(), axis=1)\n",
    "print(X_train.shape)\n",
    "print(length.shape)\n",
    "X_train = csr_matrix(np.concatenate((X_train.toarray(), length), axis=1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "incoming-office",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 981)\n",
      "(1017, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1017, 982)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = np.expand_dims(data_test['content'].apply(len).to_numpy(), axis=1)\n",
    "print(X_test.shape)\n",
    "print(length.shape)\n",
    "X_test = csr_matrix(np.concatenate((X_test.toarray(), length), axis=1))\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "restricted-census",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16100, number of negative: 3900\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 3.620550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 50997\n",
      "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 982\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.805000 -> initscore=1.417843\n",
      "[LightGBM] [Info] Start training from score 1.417843\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "bst = lgb.train(param, train_data, num_round)\n",
    "\n",
    "y_pred = bst.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "american-texture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.89      0.93       313\n",
      "           1       0.95      0.99      0.97       704\n",
      "\n",
      "    accuracy                           0.96      1017\n",
      "   macro avg       0.96      0.94      0.95      1017\n",
      "weighted avg       0.96      0.96      0.96      1017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "thirty-worth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f5d9d4fe050>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.save_model('./model/ads-detect-1-20200125.mdl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-auditor",
   "metadata": {},
   "source": [
    "## efficiency"
   ]
  },
  {
   "cell_type": "raw",
   "id": "overall-bonus",
   "metadata": {},
   "source": [
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(5)]\n",
    "\n",
    "preds, clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "transparent-peoples",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.title(\"Score\")\n",
    "\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\", color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-teens",
   "metadata": {},
   "source": [
    "## tune"
   ]
  },
  {
   "cell_type": "raw",
   "id": "casual-settlement",
   "metadata": {},
   "source": [
    "y_pred, _, _, _, _ = benchmark(ComplementNB(alpha=.1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "chronic-broadcasting",
   "metadata": {},
   "source": [
    "y_pred, _, _, _, _ = benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "rural-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "worth-lecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyh/anaconda3/envs/tf2.4/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df = data_test[['label', 'pred', 'content']]\n",
    "df['tokens'] = df['content'].apply(split2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "similar-mississippi",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>收个功勋号！</td>\n",
       "      <td>[收, 个, 功, 勋, 号, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>兄弟来新游戏试玩不？人多**好</td>\n",
       "      <td>[兄, 弟, 来, 新, 游, 戏, 试, 玩, 不, 人, 多, 好, &lt;special-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>加微信好友。</td>\n",
       "      <td>[+, 微, 好, 友, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>嫁一下**徽信xsw767拉你进群，领取礼包大家一起玩</td>\n",
       "      <td>[+, 微, &lt;contact&gt;, 拉, 进, 群, ,, 领, 取, 礼, 包, 大, 家...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>你那还有礼包码吗</td>\n",
       "      <td>[还, 有, 礼, 包, 码]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>你打公告我打资源号位置</td>\n",
       "      <td>[打, 公, 告, 打, 资, 源, 号, 位, 置]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>我下装备你过来，不行再下将</td>\n",
       "      <td>[下, 装, 备, 过, 来, ,, 不, 行, 再, 下, 将]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>战力9-12万v1想刷军功的私聊我</td>\n",
       "      <td>[战, 力, &lt;num-3&gt;, 万, 微, &lt;contact&gt;, 想, 刷, 军, 功, 私...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>不是，我说的让你们看看要不要资源</td>\n",
       "      <td>[不, 是, ,, 说, 让, 看, 看, 要, 不, 要, 资, 源]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>招手游代理或兼职，拥有个人代理后台，周结算，0加盟费，合作即可签合同，公司扶持，想了解的可以...</td>\n",
       "      <td>[招, 手, 游, 代, 理, 或, &lt;unk&gt;, &lt;unk&gt;, ,, &lt;unk&gt;, 有, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>招手游代理兼职，无需加盟费，**后台，合同模式，公司扶持政策，想了解的可以私聊我</td>\n",
       "      <td>[招, 手, 游, 代, 理, &lt;unk&gt;, &lt;unk&gt;, ,, 无, 需, +, 盟, 费...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>出号！一红，三的卢</td>\n",
       "      <td>[出, 号, 一, 红, ,, 三, &lt;unk&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>开仓吃饭了，威z506420409</td>\n",
       "      <td>[开, 仓, 吃, 饭, ,, 微, &lt;contact&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>「开仓吃饭」「{localization:189-393}，88965」</td>\n",
       "      <td>[开, 仓, 吃, 饭, &lt;loc&gt;, ,, &lt;num-5&gt;, &lt;special-char&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>出h吗</td>\n",
       "      <td>[出, h]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>看公告进群拿礼包和攻略啊</td>\n",
       "      <td>[看, 公, 告, 进, 群, 拿, 礼, 包, 和, 攻, 略]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>为实现该产品大力推广，从现在开始截止到12月7号凡是只要购买此任何一个（产品就送至尊月卡12...</td>\n",
       "      <td>[为, 实, 现, 该, &lt;unk&gt;, 品, 大, 力, 推, 广, ,, 从, 现, 在,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>朋友，就差你还没伽老大了，老大\\/X：1505080401 谢谢配合</td>\n",
       "      <td>[朋, 友, ,, 差, 还, &lt;unk&gt;, 老, 大, ,, 老, 大, &lt;contact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>出h嘛</td>\n",
       "      <td>[出, h]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>开仓 {localization:189-393}，88965</td>\n",
       "      <td>[开, 仓, &lt;loc&gt;, ,, &lt;num-5&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>你好，你这个号打算卖吗？</td>\n",
       "      <td>[好, ,, 这, 个, 号, 打, 算, 卖, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>你好，你这个号打算卖吗</td>\n",
       "      <td>[好, ,, 这, 个, 号, 打, 算, 卖]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>晚上要打城吗？不打我要买资源了</td>\n",
       "      <td>[晚, 上, 要, 打, 城, 不, 打, 要, 买, 资, 源, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>推荐大家两个网络书作者，高月和六如和尚，他俩的架空文推荐大家看一看，写的很好。</td>\n",
       "      <td>[推, &lt;unk&gt;, 大, 家, 两, 个, &lt;unk&gt;, &lt;unk&gt;, 书, 作, 者, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>10=4e,负重200</td>\n",
       "      <td>[&lt;contact&gt;, ,, 负, 重, &lt;num-3&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>你号给我吧</td>\n",
       "      <td>[号, 给]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>加你好友好吗</td>\n",
       "      <td>[+, 好, 友, 好]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>关羽张辽孙策吕布免领+q：2043603184，更有五个**码</td>\n",
       "      <td>[关, 羽, 张, &lt;unk&gt;, 孙, 策, &lt;unk&gt;, 布, 免, 领, +, &lt;con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>没有领到648充值卡的兄弟抓紧了，每天都有发，名额有限，+V：LGC44055,先到先得</td>\n",
       "      <td>[有, 领, 到, &lt;num-3&gt;, 充, 值, 卡, 兄, 弟, &lt;unk&gt;, 紧, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>帝国元首，几块钱的资源都买不起吗？曾经还是团友呢，真是高看你</td>\n",
       "      <td>[帝, 国, 元, 首, ,, 几, 块, 钱, 资, 源, 都, 买, 不, 起, &lt;un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>常玩的兄弟茄徵新ＳＬＲ８８２没加的一律当机器人提掉，来群换图集貂蝉，送花送金币</td>\n",
       "      <td>[常, 玩, 兄, 弟, +, 微, &lt;contact&gt;, +, 一, &lt;unk&gt;, 当, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>大家都加一下**微信 lf036x 进讨论组 拿礼包码 和300w的粮* ，大家一起玩。差你...</td>\n",
       "      <td>[大, 家, 都, +, 微, &lt;contact&gt;, 进, 讨, 论, 组, 拿, 礼, 包...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>你好 你这个号打算卖吗</td>\n",
       "      <td>[好, 这, 个, 号, 打, 算, 卖]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pred                                            content  \\\n",
       "61       -1     1                                             收个功勋号！   \n",
       "122      -1     1                                    兄弟来新游戏试玩不？人多**好   \n",
       "128      -1     1                                             加微信好友。   \n",
       "237      -1     1                        嫁一下**徽信xsw767拉你进群，领取礼包大家一起玩   \n",
       "241      -1     1                                           你那还有礼包码吗   \n",
       "244      -1     1                                        你打公告我打资源号位置   \n",
       "250      -1     1                                      我下装备你过来，不行再下将   \n",
       "258      -1     1                                  战力9-12万v1想刷军功的私聊我   \n",
       "264      -1     1                                   不是，我说的让你们看看要不要资源   \n",
       "314      -1     1  招手游代理或兼职，拥有个人代理后台，周结算，0加盟费，合作即可签合同，公司扶持，想了解的可以...   \n",
       "317      -1     1           招手游代理兼职，无需加盟费，**后台，合同模式，公司扶持政策，想了解的可以私聊我   \n",
       "325      -1     1                                          出号！一红，三的卢   \n",
       "387      -1     1                                  开仓吃饭了，威z506420409   \n",
       "392      -1     1               「开仓吃饭」「{localization:189-393}，88965」   \n",
       "394      -1     1                                                出h吗   \n",
       "502      -1     1                                       看公告进群拿礼包和攻略啊   \n",
       "533      -1     1  为实现该产品大力推广，从现在开始截止到12月7号凡是只要购买此任何一个（产品就送至尊月卡12...   \n",
       "550      -1     1                 朋友，就差你还没伽老大了，老大\\/X：1505080401 谢谢配合   \n",
       "552      -1     1                                                出h嘛   \n",
       "597      -1     1                    开仓 {localization:189-393}，88965   \n",
       "627      -1     1                                       你好，你这个号打算卖吗？   \n",
       "679      -1     1                                        你好，你这个号打算卖吗   \n",
       "687      -1     1                                    晚上要打城吗？不打我要买资源了   \n",
       "726      -1     1            推荐大家两个网络书作者，高月和六如和尚，他俩的架空文推荐大家看一看，写的很好。   \n",
       "922      -1     1                                        10=4e,负重200   \n",
       "928      -1     1                                              你号给我吧   \n",
       "934      -1     1                                             加你好友好吗   \n",
       "936      -1     1                    关羽张辽孙策吕布免领+q：2043603184，更有五个**码   \n",
       "944      -1     1       没有领到648充值卡的兄弟抓紧了，每天都有发，名额有限，+V：LGC44055,先到先得   \n",
       "960      -1     1                     帝国元首，几块钱的资源都买不起吗？曾经还是团友呢，真是高看你   \n",
       "987      -1     1            常玩的兄弟茄徵新ＳＬＲ８８２没加的一律当机器人提掉，来群换图集貂蝉，送花送金币   \n",
       "990      -1     1  大家都加一下**微信 lf036x 进讨论组 拿礼包码 和300w的粮* ，大家一起玩。差你...   \n",
       "1005     -1     1                                        你好 你这个号打算卖吗   \n",
       "\n",
       "                                                 tokens  \n",
       "61                      [收, 个, 功, 勋, 号, <special-char>]  \n",
       "122   [兄, 弟, 来, 新, 游, 戏, 试, 玩, 不, 人, 多, 好, <special-...  \n",
       "128                        [+, 微, 好, 友, <special-char>]  \n",
       "237   [+, 微, <contact>, 拉, 进, 群, ,, 领, 取, 礼, 包, 大, 家...  \n",
       "241                                     [还, 有, 礼, 包, 码]  \n",
       "244                         [打, 公, 告, 打, 资, 源, 号, 位, 置]  \n",
       "250                   [下, 装, 备, 过, 来, ,, 不, 行, 再, 下, 将]  \n",
       "258   [战, 力, <num-3>, 万, 微, <contact>, 想, 刷, 军, 功, 私...  \n",
       "264                [不, 是, ,, 说, 让, 看, 看, 要, 不, 要, 资, 源]  \n",
       "314   [招, 手, 游, 代, 理, 或, <unk>, <unk>, ,, <unk>, 有, ...  \n",
       "317   [招, 手, 游, 代, 理, <unk>, <unk>, ,, 无, 需, +, 盟, 费...  \n",
       "325           [出, 号, 一, 红, ,, 三, <unk>, <special-char>]  \n",
       "387                       [开, 仓, 吃, 饭, ,, 微, <contact>]  \n",
       "392   [开, 仓, 吃, 饭, <loc>, ,, <num-5>, <special-char>...  \n",
       "394                                              [出, h]  \n",
       "502                   [看, 公, 告, 进, 群, 拿, 礼, 包, 和, 攻, 略]  \n",
       "533   [为, 实, 现, 该, <unk>, 品, 大, 力, 推, 广, ,, 从, 现, 在,...  \n",
       "550   [朋, 友, ,, 差, 还, <unk>, 老, 大, ,, 老, 大, <contact...  \n",
       "552                                              [出, h]  \n",
       "597                           [开, 仓, <loc>, ,, <num-5>]  \n",
       "627            [好, ,, 这, 个, 号, 打, 算, 卖, <special-char>]  \n",
       "679                            [好, ,, 这, 个, 号, 打, 算, 卖]  \n",
       "687   [晚, 上, 要, 打, 城, 不, 打, 要, 买, 资, 源, <special-char>]  \n",
       "726   [推, <unk>, 大, 家, 两, 个, <unk>, <unk>, 书, 作, 者, ...  \n",
       "922       [<contact>, ,, 负, 重, <num-3>, <special-char>]  \n",
       "928                                              [号, 给]  \n",
       "934                                        [+, 好, 友, 好]  \n",
       "936   [关, 羽, 张, <unk>, 孙, 策, <unk>, 布, 免, 领, +, <con...  \n",
       "944   [有, 领, 到, <num-3>, 充, 值, 卡, 兄, 弟, <unk>, 紧, ,,...  \n",
       "960   [帝, 国, 元, 首, ,, 几, 块, 钱, 资, 源, 都, 买, 不, 起, <un...  \n",
       "987   [常, 玩, 兄, 弟, +, 微, <contact>, +, 一, <unk>, 当, ...  \n",
       "990   [大, 家, 都, +, 微, <contact>, 进, 讨, 论, 组, 拿, 礼, 包...  \n",
       "1005                              [好, 这, 个, 号, 打, 算, 卖]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[(~(df.label==df.pred)) & (df.label==-1)]\n",
    "print(df1.shape)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "lesbian-orange",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>霸服军团收吴，魏，蜀国活人，来的加 1979574312私聊</td>\n",
       "      <td>[霸, 服, &lt;corpus&gt;, 收, 吴, ,, 魏, ,, 蜀, 国, 人, ,, 来,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>新区195收人。，最强吴国军团。加weixin=13288669123</td>\n",
       "      <td>[新, 区, &lt;num-3&gt;, &lt;recruit&gt;, ,, 最, 强, 吴, 国, &lt;cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>能告诉我 开区啥价格 现在啥价格么</td>\n",
       "      <td>[能, 告, 诉, 开, 区, 啥, 价, 格, 现, 在, 啥, 价, 格]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>军团要整顿，加我微信，我拉你进核心群：571773352</td>\n",
       "      <td>[&lt;corpus&gt;, 要, 整, &lt;unk&gt;, ,, +, 微, ,, 拉, 进, &lt;unk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>兄弟在吗？我是灰长小号，十下我徽KLDY0855，进交流裙，没十的一会当机器人T了</td>\n",
       "      <td>[兄, 弟, 在, 是, &lt;unk&gt;, 长, 小, 号, ,, +, 微, &lt;contact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>没有微信号了，你那有吗</td>\n",
       "      <td>[有, 微, 号, ,, 有]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>酒馆收活人，来的私聊</td>\n",
       "      <td>[酒, &lt;unk&gt;, &lt;recruit&gt;, ,, 来, 私, 聊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>资源号</td>\n",
       "      <td>[资, 源, 号]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  pred                                    content  \\\n",
       "99       1    -1             霸服军团收吴，魏，蜀国活人，来的加 1979574312私聊   \n",
       "100      1    -1        新区195收人。，最强吴国军团。加weixin=13288669123   \n",
       "211      1    -1                          能告诉我 开区啥价格 现在啥价格么   \n",
       "454      1    -1               军团要整顿，加我微信，我拉你进核心群：571773352   \n",
       "513      1    -1  兄弟在吗？我是灰长小号，十下我徽KLDY0855，进交流裙，没十的一会当机器人T了   \n",
       "519      1    -1                                没有微信号了，你那有吗   \n",
       "689      1    -1                                 酒馆收活人，来的私聊   \n",
       "848      1    -1                                        资源号   \n",
       "\n",
       "                                                tokens  \n",
       "99   [霸, 服, <corpus>, 收, 吴, ,, 魏, ,, 蜀, 国, 人, ,, 来,...  \n",
       "100  [新, 区, <num-3>, <recruit>, ,, 最, 强, 吴, 国, <cor...  \n",
       "211            [能, 告, 诉, 开, 区, 啥, 价, 格, 现, 在, 啥, 价, 格]  \n",
       "454  [<corpus>, 要, 整, <unk>, ,, +, 微, ,, 拉, 进, <unk...  \n",
       "513  [兄, 弟, 在, 是, <unk>, 长, 小, 号, ,, +, 微, <contact...  \n",
       "519                                    [有, 微, 号, ,, 有]  \n",
       "689                  [酒, <unk>, <recruit>, ,, 来, 私, 聊]  \n",
       "848                                          [资, 源, 号]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[(~(df.label==df.pred)) & (df.label==1)]\n",
    "print(df2.shape)\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
