{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "positive-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import torch\n",
    "import pickle\n",
    "import transformers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "explicit-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "allied-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abroad-quebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-06 16:36:47 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
      "2021-04-06 16:36:47 DEBUG https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2021-04-06 16:36:47 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
      "2021-04-06 16:36:48 DEBUG https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/sentencepiece.bpe.model HTTP/1.1\" 200 0\n",
      "2021-04-06 16:36:48 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
      "2021-04-06 16:36:49 DEBUG https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/tokenizer.json HTTP/1.1\" 200 0\n",
      "Building model \u001b[5m\u001b[33m...\u001b[0m\u001b[0m2021-04-06 16:36:50 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
      "2021-04-06 16:36:50 DEBUG https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2021-04-06 16:36:51 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
      "2021-04-06 16:36:51 DEBUG https://huggingface.co:443 \"HEAD /xlm-roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "Moving model to GPUs [0] \u001b[5m\u001b[33m...\u001b[0m\u001b[                          \r"
     ]
    }
   ],
   "source": [
    "from tokenizer import NormalizerSGZChat\n",
    "from tokenizer import TokenizerSGZChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "biological-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seeing-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.X[index])\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask'] # sentence 有效token位置掩码\n",
    "        token_type_ids = inputs[\"token_type_ids\"] # 多sentence(s)合并为一个sentence时，不同sentence的掩码\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \n",
    "            'targets': torch.tensor(self.y[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "distributed-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(model_name, X_train, y_train, X_test, y_test, MAX_LEN):\n",
    "\n",
    "    # tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    tokenizer = TokenizerSGZChat.from_pretrained(model_name)\n",
    "    vocab = []\n",
    "    vocab.extend(NormalizerSGZChat().special_tokens)\n",
    "    for text in X_train:\n",
    "        vocab.extend(tokenizer.tokenize(text))\n",
    "    vocab = {token:i for i,token in enumerate(sorted(list(set(vocab))))}\n",
    "    tokenizer.vocab = vocab\n",
    "    \n",
    "    training_set = CustomDataset(X_train, y_train, tokenizer, MAX_LEN)\n",
    "    testing_set = CustomDataset(X_test, y_test, tokenizer, MAX_LEN)\n",
    "    \n",
    "    return training_set, testing_set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
