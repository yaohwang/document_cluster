{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "# path = os.getcwd()\n",
    "# os.chdir(os.path.join('..', '..', 'notebook_format'))\n",
    "\n",
    "# from formats import load_style\n",
    "# load_style(plot_style=False)\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(path)\n",
    "\n",
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "# %load_ext watermark\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "\n",
    "import time\n",
    "import fasttext\n",
    "import tokenizers\n",
    "\n",
    "# %watermark -a 'Ethen' -d -t -v -p numpy,tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.implementations import BaseTokenizer\n",
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ethen8181/machine-learning/tree/master/deep_learning/multi_label/fasttext_module\n",
    "from fasttext_module.model import FasttextPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"MultiLabel-Text-Classification-with-FastText\">MultiLabel Text Classification with FastText<a class=\"anchor-link\" href=\"#MultiLabel-Text-Classification-with-FastText\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><code>__label__sauce __label__cheese How much does potato starch affect a cheese sauce recipe?\n",
    "__label__food-safety __label__acidity Dangerous pathogens capable of growing in acidic environments\n",
    "__label__cast-iron __label__stove How do I cover up the white spots on my cast iron stove?</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> This file format is expected by <a href=\"https://fasttext.cc/\">Fasttext</a>, the library we'll be using to train our tag classifier.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Quick-Introduction-to-Fasttext\">Quick Introduction to Fasttext<a class=\"anchor-link\" href=\"#Quick-Introduction-to-Fasttext\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Given a word, predict me which other words should go around (skipgram).</li>\n",
    "<li>Given a sentence with a missing word, find me the missing word (cbow).</li>\n",
    "<li>Given a sentence, tell me which label corresponds to this sentence (classification).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Data-Preparation\">Data Preparation<a class=\"anchor-link\" href=\"#Data-Preparation\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: /data2/wangyh/anaconda3/lib/libuuid.so.1: no version information available (required by wget)\n",
      "--2021-02-05 13:54:17--  https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 457609 (447K) [application/x-tar]\n",
      "Saving to: ‘data/cooking.stackexchange.tar.gz’\n",
      "\n",
      "cooking.stackexchan 100%[===================>] 446.88K   493KB/s    in 0.9s    \n",
      "\n",
      "2021-02-05 13:54:20 (493 KB/s) - ‘data/cooking.stackexchange.tar.gz’ saved [457609/457609]\n",
      "\n",
      "cooking.stackexchange.id\n",
      "cooking.stackexchange.txt\n",
      "readme.txt\n"
     ]
    }
   ],
   "source": [
    "# download the data and un-tar it under the 'data' folder\n",
    "\n",
    "# -P or --directory-prefix specifies which directory to download the data to\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz -P data\n",
    "    \n",
    "# -C specifies the target directory to extract an archive to\n",
    "!tar xvzf data/cooking.stackexchange.tar.gz -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__sauce __label__cheese How much does potato starch affect a cheese sauce recipe?\r\n",
      "__label__food-safety __label__acidity Dangerous pathogens capable of growing in acidic environments\r\n",
      "__label__cast-iron __label__stove How do I cover up the white spots on my cast iron stove?\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 data/cooking.stackexchange.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_file(input_path: str,\n",
    "                          output_path_train: str,\n",
    "                          output_path_test: str,\n",
    "                          test_size: float,\n",
    "                          random_state: int=1234,\n",
    "                          encoding: str='utf-8',\n",
    "                          verbose: bool=True):\n",
    "    \n",
    "    random.seed(random_state)\n",
    "\n",
    "    # we record the number of data in the training and test\n",
    "    count_train = 0\n",
    "    count_test = 0\n",
    "    train_range = 1 - test_size\n",
    "\n",
    "    with open(input_path, encoding=encoding) as f_in, \\\n",
    "         open(output_path_train, 'w', encoding=encoding) as f_train, \\\n",
    "         open(output_path_test, 'w', encoding=encoding) as f_test:\n",
    "\n",
    "        for line in f_in:\n",
    "            random_num = random.random()\n",
    "            if random_num < train_range:\n",
    "                f_train.write(line)\n",
    "                count_train += 1\n",
    "            else:\n",
    "                f_test.write(line)\n",
    "                count_test += 1\n",
    "\n",
    "    if verbose:\n",
    "        print('train size: ', count_train)\n",
    "        print('test size: ', count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepend_file_name(path: str, name: str) -> str:\n",
    "    \"\"\"\n",
    "    e.g. data/cooking.stackexchange.txt\n",
    "    prepend 'train' to the base file name\n",
    "    data/train_cooking.stackexchange.txt\n",
    "    \"\"\"\n",
    "    directory = os.path.dirname(path)\n",
    "    file_name = os.path.basename(path)\n",
    "    return os.path.join(directory, name + '_' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  12297\n",
      "test size:  3107\n",
      "train path:  data/train_cooking.stackexchange.txt\n",
      "test path:  data/test_cooking.stackexchange.txt\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "test_size = 0.2\n",
    "input_path = os.path.join(data_dir, 'cooking.stackexchange.txt')\n",
    "input_path_train = prepend_file_name(input_path, 'train')\n",
    "input_path_test = prepend_file_name(input_path, 'test')\n",
    "random_state = 1234\n",
    "encoding = 'utf-8'\n",
    "\n",
    "train_test_split_file(input_path, input_path_train, input_path_test, test_size, random_state, encoding)\n",
    "print('train path: ', input_path_train)\n",
    "print('test path: ', input_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Model-Training\">Model Training<a class=\"anchor-link\" href=\"#Model-Training\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We can refer to the full list of parameters from <a href=\"https://fasttext.cc/docs/en/python-module.html#train_supervised-parameters\">Fasttext's documentation page</a>. Like with all machine learning models, feel free to experiment with various hyperparameters, and see which one leads to better performance.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  14496\n",
      "label size:  733\n",
      "example vocab:  ['</s>', 'to', 'a', 'How', 'the']\n",
      "example label:  ['__label__baking', '__label__food-safety', '__label__substitutions', '__label__equipment', '__label__bread']\n"
     ]
    }
   ],
   "source": [
    "# lr = learning rate\n",
    "# lrUpdateRate similar to batch size\n",
    "fasttext_params = {\n",
    "    'input': input_path_train,\n",
    "    'lr': 0.1,\n",
    "    'lrUpdateRate': 1000,\n",
    "    'thread': 8,\n",
    "    'epoch': 10,\n",
    "    'wordNgrams': 1,\n",
    "    'dim': 100,\n",
    "    'loss': 'ova'\n",
    "}\n",
    "model = fasttext.train_supervised(**fasttext_params)\n",
    "\n",
    "print('vocab size: ', len(model.words))\n",
    "print('label size: ', len(model.labels))\n",
    "print('example vocab: ', model.words[:5])\n",
    "print('example label: ', model.labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Although not used here, fasttext has a parameter called <code>bucket</code>. It can be a bit unintuitive what the parameter controls. We note down the <a href=\"https://github.com/facebookresearch/fastText/issues/641\">explanation provided by the package maintainer</a>.</p>\n",
    "<blockquote><p>The size of the model will increase linearly with the number of buckets. The size of the input matrix is DIM x (VS + BS), where VS is the number of words in the vocabulary and BS is the number of buckets. The number of buckets does not have other influence on the model size.\n",
    "The buckets are used for hashed features (such as character ngrams or word ngrams), which are used in addition to word features. In the input matrix, each word is represented by a vector, and the additional ngram features are represented by a fixed number of vectors (which corresponds to the number of buckets).</p>\n",
    "</blockquote>\n",
    "<p>The loss function that we've specified is one versus all, <code>ova</code> for short. This type of loss function handles the multiple labels by building independent binary classifiers for each label.</p>\n",
    "<p>Upon training the model, we can take a look at the prediction generated by the model via passing a question to the <code>.predict</code> method.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__sauce', '__label__cheese'), array([0.80807722, 0.56986266]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'How much does potato starch affect a cheese sauce recipe?'\n",
    "model.predict(text, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The annotated tags for this question were <code>__label__sauce</code> and <code>__label__cheese</code>. Meaning we got both the prediction correct when asking for the top 2 tags. i.e. the precision@2 (precision at 2) for this example is 100%.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__food-safety', '__label__storage-method'),\n",
       " array([0.21734752, 0.06561483]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Dangerous pathogens capable of growing in acidic environments'\n",
    "model.predict(text, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>In this example, the annotated tags were <code>__label__food-safety</code> and <code>__label__acidity</code>. In other words, 1 of our predicted tag was wrong, hence the precision@2 is 50%.</p>\n",
    "<p>Notice the second prediction's score is pretty low, when calling the <code>.predict</code> method, we can also provide a threshold to cutoff predictions lower than that value.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__food-safety',), array([0.21734752]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Dangerous pathogens capable of growing in acidic environments'\n",
    "model.predict(text, k=2, threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The <code>.predict</code> method also supports batch prediction, where we pass in a list of text.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['__label__sauce', '__label__cheese'],\n",
       "  ['__label__food-safety', '__label__storage-method']],\n",
       " [array([0.8080772 , 0.56986266], dtype=float32),\n",
       "  array([0.21734752, 0.06561483], dtype=float32)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'How much does potato starch affect a cheese sauce recipe?',\n",
    "    'Dangerous pathogens capable of growing in acidic environments'\n",
    "]\n",
    "\n",
    "batch_results = model.predict(texts, k=2)\n",
    "batch_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>To perform this type of evaluation all together on our train and test file, we can leverage the <code>.test</code> method from the model to evaluate the overall precision and recall metrics.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "?model.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model, input_path, k):\n",
    "    num_records, precision_at_k, recall_at_k = model.test(input_path, k)\n",
    "    f1_at_k = 2 * (precision_at_k * recall_at_k) / (precision_at_k + recall_at_k)\n",
    "\n",
    "    print(\"records\\t{}\".format(num_records))\n",
    "    print(\"Precision@{}\\t{:.3f}\".format(k, precision_at_k))\n",
    "    print(\"Recall@{}\\t{:.3f}\".format(k, recall_at_k))\n",
    "    print(\"F1@{}\\t{:.3f}\".format(k, f1_at_k))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train metrics:\n",
      "records\t12297\n",
      "Precision@1\t0.491\n",
      "Recall@1\t0.213\n",
      "F1@1\t0.297\n",
      "\n",
      "test metrics:\n",
      "records\t3107\n",
      "Precision@1\t0.411\n",
      "Recall@1\t0.177\n",
      "F1@1\t0.248\n",
      "\n",
      "train metrics:\n",
      "records\t12297\n",
      "Precision@2\t0.363\n",
      "Recall@2\t0.315\n",
      "F1@2\t0.337\n",
      "\n",
      "test metrics:\n",
      "records\t3107\n",
      "Precision@2\t0.310\n",
      "Recall@2\t0.268\n",
      "F1@2\t0.287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(1, 3):\n",
    "    print('train metrics:')\n",
    "    print_results(model, input_path_train, k)\n",
    "\n",
    "    print('test metrics:')\n",
    "    print_results(model, input_path_test, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Tokenizer\">Tokenizer<a class=\"anchor-link\" href=\"#Tokenizer\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>using <a href=\"https://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/subword/bpe.ipynb\">Byte Pair Encoding</a> to tokenize the raw text into subwords.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTTEXT_LABEL = '__label__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_file(input_path: str, output_path: str, encoding: str='utf-8'):\n",
    "    with open(input_path, encoding=encoding) as f_in, \\\n",
    "         open(output_path, 'w', encoding=encoding) as f_out:\n",
    "\n",
    "        for line in f_in:\n",
    "            try:\n",
    "                tokens = []\n",
    "                for token in line.split(' '):\n",
    "                    if FASTTEXT_LABEL not in token:\n",
    "                        tokens.append(token)\n",
    "\n",
    "                text = ' '.join(tokens)\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "\n",
    "            f_out.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text only train file:  data/text_train_cooking.stackexchange.txt\n"
     ]
    }
   ],
   "source": [
    "text_input_path = prepend_file_name(input_path_train, 'text')\n",
    "print('text only train file: ', text_input_path)\n",
    "\n",
    "create_text_file(input_path_train, text_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dangerous pathogens capable of growing in acidic environments\r\n",
      "How do I cover up the white spots on my cast iron stove?\r\n",
      "What's the purpose of a bread box?\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 data/text_train_cooking.stackexchange.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>For our tokenizer, we'll be using <a href=\"https://github.com/huggingface/tokenizers/tree/master/bindings/python\">HuggingFace's Tokenizers</a>. Similar to Fasttext, the input expects the path to our text.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer(lowercase=True)\n",
    "\n",
    "tokenizer.train(\n",
    "    text_input_path,\n",
    "    vocab_size=10000,\n",
    "    min_frequency=2,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>After training the tokenizer, we can use it to tokenize any new incoming text.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=11, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'How much does potato starch affect a cheese sauce recipe?'\n",
    "encoded_text = tokenizer.encode(text)\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how',\n",
       " 'Ġmuch',\n",
       " 'Ġdoes',\n",
       " 'Ġpotato',\n",
       " 'Ġstarch',\n",
       " 'Ġaffect',\n",
       " 'Ġa',\n",
       " 'Ġcheese',\n",
       " 'Ġsauce',\n",
       " 'Ġrecipe',\n",
       " '?']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We now read in the original training/test file and tokenized the text part with our tokenizer, and write it back to a new file. We'll train the fasttext model on this new tokenized file.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(tokenizer: BaseTokenizer, text: str) -> str:\n",
    "    \"\"\"\n",
    "    Given the raw text, tokenize it using the trained tokenizer and\n",
    "    outputs the tokenized tetx.\n",
    "    \"\"\"\n",
    "    return ' '.join(tokenizer.encode(text).tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenized_file(input_path: str, output_path: str,\n",
    "                          tokenizer: BaseTokenizer, encoding: str='utf-8'):\n",
    "    \n",
    "    with open(input_path, encoding=encoding) as f_in, \\\n",
    "         open(output_path, 'w', encoding=encoding) as f_out:\n",
    "\n",
    "        for line in f_in:\n",
    "            try:\n",
    "                # the labels remains untouched during the preprocessing step as its\n",
    "                # already in a format that fasttext can consume\n",
    "                tokens = []\n",
    "                labels = []\n",
    "                \n",
    "                for token in line.split(' '):\n",
    "                    if FASTTEXT_LABEL in token:\n",
    "                        labels.append(token)\n",
    "                    else:\n",
    "                        tokens.append(token)\n",
    "\n",
    "                text = ' '.join(tokens)\n",
    "                label = ' '.join(labels)\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "\n",
    "            tokenized_text = tokenize_text(tokenizer, text)\n",
    "            new_line = label + ' ' + tokenized_text\n",
    "            \n",
    "            f_out.write(new_line)\n",
    "            f_out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized train file:  data/tokenized_train_cooking.stackexchange.txt\n",
      "tokenized test file:  data/tokenized_test_cooking.stackexchange.txt\n"
     ]
    }
   ],
   "source": [
    "input_path_train_tokenized = prepend_file_name(input_path_train, 'tokenized')\n",
    "print('tokenized train file: ', input_path_train_tokenized)\n",
    "create_tokenized_file(input_path_train, input_path_train_tokenized, tokenizer)\n",
    "\n",
    "input_path_test_tokenized = prepend_file_name(input_path_test, 'tokenized')\n",
    "print('tokenized test file: ', input_path_test_tokenized)\n",
    "create_tokenized_file(input_path_test, input_path_test_tokenized, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__food-safety __label__acidity dang er ous Ġpat hog ens Ġcapable Ġof Ġgrowing Ġin Ġacidic Ġenviron ments Ċ\r\n",
      "__label__cast-iron __label__stove how Ġdo Ġi Ġcover Ġup Ġthe Ġwhite Ġspots Ġon Ġmy Ġcast Ġiron Ġstove ? Ċ\r\n",
      "__label__storage-method __label__equipment __label__bread what 's Ġthe Ġpurpose Ġof Ġa Ġbread Ġbox ? Ċ\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 data/tokenized_train_cooking.stackexchange.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  7342\n",
      "label size:  733\n",
      "example vocab:  ['</s>', 'Ċ', '?', 'Ġto', 'Ġa']\n",
      "example label:  ['__label__baking', '__label__food-safety', '__label__substitutions', '__label__equipment', '__label__bread']\n"
     ]
    }
   ],
   "source": [
    "fasttext_params['input'] = input_path_train_tokenized\n",
    "tokenized_model = fasttext.train_supervised(**fasttext_params)\n",
    "\n",
    "print('vocab size: ', len(tokenized_model.words))\n",
    "print('label size: ', len(tokenized_model.labels))\n",
    "print('example vocab: ', tokenized_model.words[:5])\n",
    "print('example label: ', tokenized_model.labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We print out the evaluation metric for the new model based on tokenized text and compare it with the original model that was trained on the raw text.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train metrics:\n",
      "records\t12297\n",
      "Precision@1\t0.498\n",
      "Recall@1\t0.216\n",
      "F1@1\t0.301\n",
      "\n",
      "test metrics:\n",
      "records\t3107\n",
      "Precision@1\t0.454\n",
      "Recall@1\t0.196\n",
      "F1@1\t0.274\n",
      "\n",
      "train metrics:\n",
      "records\t12297\n",
      "Precision@2\t0.366\n",
      "Recall@2\t0.318\n",
      "F1@2\t0.341\n",
      "\n",
      "test metrics:\n",
      "records\t3107\n",
      "Precision@2\t0.331\n",
      "Recall@2\t0.285\n",
      "F1@2\t0.306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(1, 3):\n",
    "    print('train metrics:')\n",
    "    print_results(tokenized_model, input_path_train_tokenized, k)\n",
    "\n",
    "    print('test metrics:')\n",
    "    print_results(tokenized_model, input_path_test_tokenized, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train metrics:\n",
      "records\t12297\n",
      "Precision@1\t0.491\n",
      "Recall@1\t0.213\n",
      "F1@1\t0.297\n",
      "\n",
      "test metrics:\n",
      "records\t3107\n",
      "Precision@1\t0.411\n",
      "Recall@1\t0.177\n",
      "F1@1\t0.248\n",
      "\n",
      "train metrics:\n",
      "records\t12297\n",
      "Precision@2\t0.363\n",
      "Recall@2\t0.315\n",
      "F1@2\t0.337\n",
      "\n",
      "test metrics:\n",
      "records\t3107\n",
      "Precision@2\t0.310\n",
      "Recall@2\t0.268\n",
      "F1@2\t0.287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in range(1, 3):\n",
    "    print('train metrics:')\n",
    "    print_results(model, input_path_train, k)\n",
    "\n",
    "    print('test metrics:')\n",
    "    print_results(model, input_path_test, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Both the tokenizer and fasttext model has API to save and load the model.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'model'\n",
    "if not os.path.isdir(directory):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "tokenizer_checkpoint = os.path.join(directory, 'tokenizer.json')\n",
    "tokenizer.save(tokenizer_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_model_checkpoint = os.path.join(directory, 'tokenized_cooking_model.fasttext')\n",
    "tokenized_model.save_model(tokenized_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_tokenizer = Tokenizer.from_file(tokenizer_checkpoint)\n",
    "loaded_model = fasttext.load_model(tokenized_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how',\n",
       " 'Ġmuch',\n",
       " 'Ġdoes',\n",
       " 'Ġpotato',\n",
       " 'Ġstarch',\n",
       " 'Ġaffect',\n",
       " 'Ġa',\n",
       " 'Ġcheese',\n",
       " 'Ġsauce',\n",
       " 'Ġrecipe',\n",
       " '?']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = loaded_tokenizer.encode(text)\n",
    "encoded_text.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Now, to predict new labels for incoming text, we need to tokenize the raw text before feeding it to the model.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, tokenizer, model, k, threshold=0.1):\n",
    "    tokenized_text = tokenize_text(tokenizer, text)\n",
    "    return model.predict(tokenized_text, k=k, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__baking', '__label__bread', '__label__cookies'),\n",
       " array([0.98968184, 0.96886617, 0.19683622]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Which baking dish is best to bake a banana bread ?'\n",
    "predict(text, loaded_tokenizer, loaded_model, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(texts, tokenizer, model, k, threshold=0.1):\n",
    "    tokenized_texts = [tokenize_text(tokenizer, text) for text in texts]\n",
    "    return model.predict(tokenized_texts, k=k, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['__label__baking', '__label__bread'],\n",
       "  ['__label__equipment', '__label__coffee'],\n",
       "  ['__label__cast-iron', '__label__equipment']],\n",
       " [array([0.98968184, 0.96886617], dtype=float32),\n",
       "  array([0.37023538, 0.16452648], dtype=float32),\n",
       "  array([0.6150979 , 0.35578486], dtype=float32)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    'Which baking dish is best to bake a banana bread ?',\n",
    "    'Why not put knives in the dishwasher?',\n",
    "    'How do I cover up the white spots on my cast iron stove?'\n",
    "]\n",
    "batch_results = batch_predict(texts, loaded_tokenizer, loaded_model, k=2, threshold=0.0)\n",
    "batch_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Fasttext-Text-Classification-Pipeline\">Fasttext Text Classification Pipeline<a class=\"anchor-link\" href=\"#Fasttext-Text-Classification-Pipeline\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The following provides a sample code on how to wrap a <code>FasttextPipeline</code> class on top of the fasttext model to allow for hyperparameter tuning. The <a href=\"https://github.com/ethen8181/machine-learning/tree/master/deep_learning/multi_label/fasttext_module\"><code>fasttext_module</code></a> can be found here for those interested.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'cooking'\n",
    "\n",
    "fasttext_params = {\n",
    "    \"lr\": 0.1,\n",
    "    \"lrUpdateRate\": 1000,\n",
    "    \"thread\": 6,\n",
    "    \"epoch\": 10,\n",
    "    \"wordNgrams\": 1,\n",
    "    \"dim\": 100,\n",
    "    \"loss\": \"ova\"\n",
    "}\n",
    "\n",
    "fasttext_hyper_params = {\n",
    "    'dim': [80, 100],\n",
    "    'epoch': [15]\n",
    "}\n",
    "\n",
    "fasttext_search_parameters =  {\n",
    "    \"n_iter\": 2,\n",
    "    \"n_jobs\": 1,\n",
    "    \"verbose\": 1,\n",
    "    \"scoring\": \"f1@1\",\n",
    "    \"random_state\": 1234\n",
    "}\n",
    "\n",
    "val_size = 0.1\n",
    "split_random_state = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyh/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass random_state=1234 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>epoch</th>\n",
       "      <th>dim</th>\n",
       "      <th>train_precision@1</th>\n",
       "      <th>train_recall@1</th>\n",
       "      <th>train_f1@1</th>\n",
       "      <th>test_precision@1</th>\n",
       "      <th>test_recall@1</th>\n",
       "      <th>test_f1@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'epoch': 15, 'dim': 80}</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'epoch': 15, 'dim': 100}</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      params  epoch  dim  train_precision@1  train_recall@1  \\\n",
       "0   {'epoch': 15, 'dim': 80}     15   80              0.618           0.268   \n",
       "1  {'epoch': 15, 'dim': 100}     15  100              0.617           0.268   \n",
       "\n",
       "   train_f1@1  test_precision@1  test_recall@1  test_f1@1  \n",
       "0       0.374             0.482          0.210      0.292  \n",
       "1       0.373             0.477          0.207      0.289  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_pipeline = FasttextPipeline(model_id,\n",
    "                                     fasttext_params,\n",
    "                                     fasttext_hyper_params,\n",
    "                                     fasttext_search_parameters)\n",
    "\n",
    "# fit the pipeline by giving it the training text file and specify the\n",
    "# size of the validation split that will be used for hyperparameter tuning\n",
    "\n",
    "# note that here the file in input_path_train should already be tokenized and\n",
    "# in the format that fasttext expects\n",
    "fasttext_pipeline.fit_file(input_path_train, val_size, split_random_state)\n",
    "\n",
    "# check the hyperparameter tuning result stored in a pandas DataFrame\n",
    "fasttext_pipeline.df_tune_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load the model back\n",
    "model_checkpoint_dir = fasttext_pipeline.save('model')\n",
    "fasttext_pipeline_loaded = FasttextPipeline.load(model_checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train metric - num_records: 12297, precision@1: 0.644, recall@1: 0.28, f1@1: 0.39\n",
      "test metric - num_records: 3107, precision@1: 0.496, recall@1: 0.214, f1@1: 0.299\n"
     ]
    }
   ],
   "source": [
    "# compute the evaluation metric on the train and test text dataset\n",
    "k = 1\n",
    "score_str_train = fasttext_pipeline.score_str(input_path_train, k)\n",
    "score_str_test = fasttext_pipeline.score_str(input_path_test, k)\n",
    "print('train' + score_str_train)\n",
    "print('test' + score_str_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['__label__baking', '__label__bread'],\n",
       "  ['__label__equipment', '__label__cleaning'],\n",
       "  ['__label__cast-iron']],\n",
       " [array([0.9875784, 0.914911 ], dtype=float32),\n",
       "  array([0.9481645 , 0.15611489], dtype=float32),\n",
       "  array([0.60767317], dtype=float32)])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the trained model to predict on new incoming text\n",
    "k = 2\n",
    "threshold = 0.1\n",
    "texts = [\n",
    "    'Which baking dish is best to bake a banana bread ?',\n",
    "    'Why not put knives in the dishwasher?',\n",
    "    'How do I cover up the white spots on my cast iron stove?'\n",
    "]\n",
    "batch_results = fasttext_pipeline.predict(texts, k, threshold)\n",
    "batch_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Reference\">Reference<a class=\"anchor-link\" href=\"#Reference\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "<li><a href=\"https://github.com/huggingface/tokenizers/tree/master/bindings/python\">Github: Tokenizers</a></li>\n",
    "<li><a href=\"https://fasttext.cc/docs/en/supervised-tutorial.html\">Fasttext Documentation: Text Classification</a></li>\n",
    "<li><a href=\"https://www.quora.com/What-is-the-main-difference-between-word2vec-and-fastText\">Quora: What is the main difference between word2vec and fastText?</a></li>\n",
    "<li><a href=\"https://arxiv.org/abs/1607.01759\">Paper: A. Joulin, E. Grave, P. Bojanowski, T. Mikolov - Bag of Tricks for Efficient Text Classification (2016)</a></li>\n",
    "</ul>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
