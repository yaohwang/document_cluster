{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import jieba\n",
    "import pickle\n",
    "import logging\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time\n",
    "from functools import partial\n",
    "from itertools import chain\n",
    "from itertools import zip_longest\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from optparse import OptionParser\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.extmath import density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', 10**5)\n",
    "pd.set_option('display.max_colwidth', 10**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interactive():\n",
    "    return not hasattr(sys.modules['__main__'], '__file__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Option at 0x7f584f6843d0: --n_features>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = OptionParser()\n",
    "\n",
    "op.add_option(\"--report\",\n",
    "              action=\"store_true\", dest=\"print_report\", default=True,\n",
    "              help=\"Print a detailed classification report.\")\n",
    "\n",
    "op.add_option(\"--chi2_select\",\n",
    "              action=\"store\", type=\"int\", dest=\"select_chi2\",\n",
    "              help=\"Select some number of features using a chi-squared test\")\n",
    "\n",
    "op.add_option(\"--confusion_matrix\",\n",
    "              action=\"store_true\", dest=\"print_cm\",\n",
    "              help=\"Print the confusion matrix.\")\n",
    "\n",
    "op.add_option(\"--top10\",\n",
    "              action=\"store_true\", dest=\"print_top10\",\n",
    "              help=\"Print ten most discriminative terms per class for every classifier.\")\n",
    "\n",
    "op.add_option(\"--use_hashing\",\n",
    "              action=\"store_true\",\n",
    "              help=\"Use a hashing vectorizer.\")\n",
    "\n",
    "op.add_option(\"--n_features\",\n",
    "              action=\"store\", type=int, default=2 ** 16,\n",
    "              help=\"n_features when using the hashing vectorizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Values at 0x7f587c602670: {'print_report': True, 'select_chi2': None, 'print_cm': None, 'print_top10': None, 'use_hashing': None, 'n_features': 65536}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# work-around for Jupyter notebook and IPython console\n",
    "\n",
    "# opts, an object containing values for all of your options\n",
    "#     e.g. if --file takes a single string argument, then options.file will be the filename supplied by the user, \n",
    "#     or None if the user did not supply that option\n",
    "# args, the list of positional arguments leftover after parsing options\n",
    "\n",
    "argv = [] if is_interactive() else sys.argv[1:]\n",
    "(opts, args) = op.parse_args(argv)\n",
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Usage: ipykernel_launcher.py [options]\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --report              Print a detailed classification report.\n",
      "  --chi2_select=SELECT_CHI2\n",
      "                        Select some number of features using a chi-squared\n",
      "                        test\n",
      "  --confusion_matrix    Print the confusion matrix.\n",
      "  --top10               Print ten most discriminative terms per class for\n",
      "                        every classifier.\n",
      "  --use_hashing         Use a hashing vectorizer.\n",
      "  --n_features=N_FEATURES\n",
      "                        n_features when using the hashing vectorizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if len(args) > 0:\n",
    "    op.error(\"this script takes no arguments.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(__doc__)\n",
    "op.print_help()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-25 11:18:49,283 INFO NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>岀赀縁 masonghe86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>九，勾引团里有夫之妇，满脸zhi疮</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53=10w元宝+VIP13+武将+各资源1亿+Q348857676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                             content\n",
       "0    1.0                      岀赀縁 masonghe86\n",
       "1   11.0                   九，勾引团里有夫之妇，满脸zhi疮\n",
       "2    1.0  53=10w元宝+VIP13+武将+各资源1亿+Q348857676"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_excel('/home/wangyh/project/document_cluster/data/dataset_ads-20210113-1-labeled.xlsx')\n",
    "data_train = data_train[['label', 'content']]\n",
    "data_train = data_train.dropna()\n",
    "\n",
    "print(data_train.shape)\n",
    "data_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>为了军团更好地发展，资源更好地利用，大家一起作战，兄弟加微信：svip12126，组织打城，军团群里有攻略和内测老人带队，就差你一个人没加了，没加的当机器人踢了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>无兄弟，不三国195新区即将来至大佬带队，要去的可私聊我霸服了团长送老婆十对</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>全/脫/小/妹/针.人视频1对1/Q Q：2332287921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      2   \n",
       "1      2   \n",
       "2      1   \n",
       "\n",
       "                                                                            content  \n",
       "0  为了军团更好地发展，资源更好地利用，大家一起作战，兄弟加微信：svip12126，组织打城，军团群里有攻略和内测老人带队，就差你一个人没加了，没加的当机器人踢了  \n",
       "1                                            无兄弟，不三国195新区即将来至大佬带队，要去的可私聊我霸服了团长送老婆十对  \n",
       "2                                                   全/脫/小/妹/针.人视频1对1/Q Q：2332287921  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_excel('/home/wangyh/project/document_cluster/data/dataset_ads-20210120-1-labeled.xlsx')\n",
    "data_test = data_test[['label', 'content']]\n",
    "data_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    0.805\n",
       "-1.0    0.195\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.loc[data_train.label.isin([1, 9, 24]), 'label'] = -1   # ads\n",
    "data_train.loc[~(data_train.label==-1), 'label'] = 1\n",
    "\n",
    "data_train.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    0.692232\n",
       "-1    0.307768\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.loc[data_test.label.isin([1, 9, 24]), 'label'] = -1\n",
    "data_test.loc[~(data_test.label==-1), 'label'] = 1\n",
    "data_test.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = data_train.content, data_test.content\n",
    "y_train, y_test = data_train.label.tolist(), data_test.label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 documents - 0.837MB (training set)\n",
      "1017 documents - 0.061MB (test set)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train_size_mb = size_mb(X_train)\n",
    "data_test_size_mb = size_mb(X_test)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (len(X_train), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (len(X_test), data_test_size_mb))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_special(i):\n",
    "    \n",
    "    is_1 =  i in ['<unk>', '<loc>', '<contact>', '<recruit>', '<corpus>', '<colonel>']\n",
    "    is_2 = bool(re.match(r'^<num-[0-9]+>$', i))\n",
    "    \n",
    "    return is_1 or is_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_special(i):\n",
    "    return not is_special(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __replace(s):\n",
    "    if is_special(s): return s\n",
    "    \n",
    "    # 微信\n",
    "    s = s.replace('威', '微')\n",
    "    s = s.replace('徽', '微')\n",
    "    s = s.replace('徵', '微')\n",
    "    s = s.replace('亻言', '信')\n",
    "    \n",
    "    s = s.replace('微新', '微信')\n",
    "    s = s.replace('微信', '微')\n",
    "    \n",
    "    # 加\n",
    "    s = s.replace('咖', '加')\n",
    "    s = s.replace('架', '加')\n",
    "    s = s.replace('嫁', '加')\n",
    "    s = s.replace('十', '加')\n",
    "    s = s.replace('茄', '加')\n",
    "    s = s.replace('迦', '加')\n",
    "    \n",
    "    s = s.replace('加下', '加')\n",
    "    s = s.replace('加一下', '加')\n",
    "    \n",
    "    s = s.replace('加', '+')\n",
    "    \n",
    "    # 收人\n",
    "    s = s.replace('活人', '人')\n",
    "    # s = s.replace('收人', '<recruit>')\n",
    "    \n",
    "    # 团长\n",
    "    s = s.replace('圕', '团')\n",
    "    \n",
    "    # 充\n",
    "    s = s.replace('冲', '充')\n",
    "    s = s.replace('直充', '充')\n",
    "    \n",
    "    # 出\n",
    "    s = s.replace('础', '出')\n",
    "\n",
    "    # 卖\n",
    "    s = s.replace('麦', '出')\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(x):\n",
    "    return [__replace(i) for i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split util"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def chars_numbers(i):\n",
    "    \"\"\" tool\n",
    "    \"\"\"\n",
    "    \n",
    "    m = re.match('^([a-z]+)([0-9]+)$', i)\n",
    "    if m: return list(m.groups())\n",
    "    \n",
    "    m = re.match('^([0-9]+)([a-z]+)$', i)\n",
    "    if m: return list(m.groups())\n",
    "    \n",
    "    return [i]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def split_chars_numbers(x):\n",
    "    \"\"\" tool\n",
    "    \"\"\"\n",
    "    \n",
    "    return list(chain.from_iterable([chars_numbers(i) for i in x])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_regex(s, reg, flag):\n",
    "    r = re.split(reg, s)\n",
    "    if 1 >= len(r): return r\n",
    "    r = list(chain.from_iterable(zip_longest(r[:-1], [], fillvalue=flag))) + r[-1:]\n",
    "    return [i for i in r if i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_location(s):\n",
    "    return split_regex(s, r'{localization:[0-9]+\\-[0-9]+}', '<loc>')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(split_location('「开仓吃饭」「{localization:189-393}，88965」{localization:189-393}，889'))\n",
    "print(split_location('「开仓吃饭」「{localization:189-393}，88965」'))\n",
    "print(split_location('「开仓吃饭」「{localization:189-393}'))\n",
    "print(split_location('{localization:189-393}，88965」'))\n",
    "print(split_location('{localization:189-393}'))\n",
    "print(split_location('2{l4ocalization:189-393}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split terminology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __split_terminology(s, term, flag):\n",
    "    if is_special(s): return [s]\n",
    "    return split_regex(s, r'%s' % term, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_terminology(x, term, flag):\n",
    "    return list(chain.from_iterable([__split_terminology(i, term, flag) for i in x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split num + char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __split_charnum(s):\n",
    "    if is_special(s): return [s]\n",
    "    return [c for c in re.split(r'([0-9a-z]+)', s) if c]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(__split_charnum('yweighu768980k上jwio880中不为'))\n",
    "print(__split_charnum('上中不为'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_charnum(x):\n",
    "    return list(chain.from_iterable([__split_charnum(s) for s in x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(s):\n",
    "    \n",
    "    has_num = bool(re.findall(r'[0-9]+', s))\n",
    "    hasnot_other = not bool(re.findall(r'[^0-9]+', s))\n",
    "    \n",
    "    return has_num and hasnot_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_num(x):\n",
    "    \"\"\" tool\n",
    "    \"\"\"\n",
    "    \n",
    "    # return ['<num-%s>' % len(i) if i.isnumeric() else i for i in x]\n",
    "    return ['<num-%s>' % len(i) if not_special(i) and is_numeric(i) else i for i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert num + char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_charnum(s):\n",
    "    \n",
    "    has_num = bool(re.findall(r'[0-9]+', s))\n",
    "    has_char = bool(re.findall(r'[a-z]+', s))\n",
    "    hasnot_other = not bool(re.findall(r'[^a-z0-9]+', s))\n",
    "    \n",
    "    return has_num and has_char and hasnot_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_v_num(s):\n",
    "    return bool(re.match(r'v[0-9]+', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_vx_num(s):\n",
    "    return bool(re.match(r'vx[0-9]+', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_qq_num(s):\n",
    "    return bool(re.match(r'qq[0-9]+', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __convert_chars_numbers(s):\n",
    "    \n",
    "    if is_special(s): return [s]\n",
    "    \n",
    "    if is_v_num(s): return ['微', '<contact>']\n",
    "    if is_vx_num(s): return ['微', '<contact>']\n",
    "    if is_qq_num(s): return ['微', '<contact>']\n",
    "    \n",
    "    if is_charnum(s): return ['<contact>']\n",
    "    \n",
    "    return [s]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_chars_numbers(x):\n",
    "    # return ['<contact>' if not_special(i) and is_charnum(i) else i for i in x]\n",
    "    return list(chain.from_iterable([__convert_chars_numbers(s) for s in x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split char, num, chinese + special"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "s = '◢好◣oooo ┏━卖资源━┓ oooo◢天◣ ◥好◤( 乖)┃高◣┃◢功┃(乖 )◥天◤ ◢游◣ * ( ┃迁◤┃◥勋┃ ) * ◢资◣ ◥戏◤ *__)┗━じovの━┛(__* ◥源◤ __________微信jinyanzifei8__________'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __split_normal_special(s):\n",
    "    if is_special(s): return s, ''\n",
    "    \n",
    "    # TODO: wheather , . ，。blank should be in valid\n",
    "    return ''.join(re.findall(r'[,\\+a-z0-9\\u4e00-\\u9fa5]+', s)), ''.join(re.findall(r'[^,\\+a-z0-9\\u4e00-\\u9fa5]+', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_normal_special(x):\n",
    "    \n",
    "    r = [__split_normal_special(i) for i in x]\n",
    "    \n",
    "    r1, r2 = zip(*r)\n",
    "    r1 = [i for i in r1 if i]\n",
    "    r2 = [i for i in r2 if i]\n",
    "    \n",
    "    return r1, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_naive(s):\n",
    "    # return jieba.lcut(s)\n",
    "    # return jieba.lcut(s, cut_all=True)\n",
    "    # return jieba.lcut_for_search(s)\n",
    "    return list(s)\n",
    "    \n",
    "    # return jieba.lcut(s, cut_all=True) + list(s)\n",
    "    # return jieba.lcut_for_search(s) + list(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __split_once(s):\n",
    "    if is_special(s): return [s]\n",
    "    \n",
    "    # s1, s2 = split_normal_special(s)\n",
    "    \n",
    "    # return __split0(s1) + __split0(s2)\n",
    "    # return split_naive(s1) + list(s2)\n",
    "    \n",
    "    # r = split_naive(s1) + list(s)\n",
    "    \n",
    "    # r1 = split_naive(s1)\n",
    "    # r2 = list(s)\n",
    "    # r = r1 + list(set(r2)-set(r1))\n",
    "    \n",
    "    # s = replace(s)\n",
    "    # r = list(s)\n",
    "    r = split_naive(s)\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_once(x):\n",
    "    return list(chain.from_iterable([__split_once(s) for s in x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords1_usual = ['你', '我', '他', '她', '它', '们',\n",
    "                    '吧', '吗', '嘛', '啊', '阿', '呢', '呀',\n",
    "                    '的', '地', \n",
    "                    '怎', '么',\n",
    "                    '那', '哪',\n",
    "                    '就', '没', '了', '谢', '配', '合']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords1 = stopwords1_usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(x):\n",
    "    return [i for i in x if i not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def __split(s):\n",
    "    r = []\n",
    "    l = re.split(loc, s)\n",
    "    \n",
    "    for i in l[:-1]:\n",
    "        r.extend(__split1(i))\n",
    "        r.append('<loc>')\n",
    "        \n",
    "    r.extend(__split1(l[-1]))\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def split1(s):\n",
    "    s = s.lower()\n",
    "    # tokens = jieba.lcut(s, cut_all=True)\n",
    "    # tokens = __split(s)\n",
    "    tokens = split_location(s)\n",
    "    \n",
    "    # tokens = split_chars_numbers(tokens)\n",
    "    tokens = convert_chars_numbers(tokens)\n",
    "    \n",
    "    tokens = convert_num(tokens)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split1(s):\n",
    "    # preprocess\n",
    "    s = s.replace(' ', '')    # TODO: maybe all blank\n",
    "    s = s.lower()\n",
    "    s = unicodedata.normalize('NFKC', s)\n",
    "    \n",
    "    # formated\n",
    "    tokens = split_location(s)\n",
    "    \n",
    "    # normal and special-char\n",
    "    tokens, tokens_special = split_normal_special(tokens)\n",
    "    \n",
    "    # user defined\n",
    "    tokens = split_charnum(tokens)\n",
    "    tokens = convert_num(tokens)\n",
    "    tokens = convert_chars_numbers(tokens)\n",
    "    \n",
    "    # link\n",
    "    tokens = replace(tokens)\n",
    "    \n",
    "    # split\n",
    "    tokens = split_terminology(tokens, '收人', '<recruit>')\n",
    "    tokens = split_terminology(tokens, '军团', '<corpus>')\n",
    "    tokens = split_terminology(tokens, '团长', '<colonel>')\n",
    "    tokens = split_once(tokens)\n",
    "    \n",
    "    # filter\n",
    "    tokens = filter_stopwords(tokens)\n",
    "    \n",
    "    # merge tokens_special\n",
    "    # tokens += list(''.join(tokens_special))\n",
    "    tokens += ['<special-char>'] * len(''.join(tokens_special))\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# print(split1('有资源，有功勋 {localization:356-290}'))\n",
    "# print(split1('林昊天 有事找， 你架下他徽 a a z 0 1 2 4'))\n",
    "# print(split1('－－大家看角色名字，需要加ｑ７６６－６４５－８５１菿－付'))\n",
    "print(split1('军团收活人，来的加 1979574312私聊'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "split1 = list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### high freq"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=1e-2, tokenizer=split1)\n",
    "tfidf = vectorizer.fit_transform(X_train)\n",
    "        \n",
    "duration = time() - t0\n",
    "\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % tfidf.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "# feature_names"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def high_freq(x):\n",
    "    return [i for i in x if is_special(i) or (i not in feature_names)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### low freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 1.640201s at 0.510MB/s\n",
      "n_samples: 20000, n_features: 980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=1e-3, tokenizer=split1)\n",
    "tfidf = vectorizer.fit_transform(X_train)\n",
    "        \n",
    "duration = time() - t0\n",
    "\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % tfidf.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/ads-detect-1-20200125.vocab', 'wb') as f:\n",
    "    pickle.dump(feature_names, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for f in feature_names: print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_freq(x):\n",
    "    return ['<unk>' if i not in feature_names else i for i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split2(s):\n",
    "    # return low_freq(split1(s))\n",
    "\n",
    "    tokens = split1(s)\n",
    "    # tokens = high_freq(tokens)\n",
    "    tokens = low_freq(tokens)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['tokens'] = data_train['content'].apply(split2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_train.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 3.236342s at 0.259MB/s\n",
      "n_samples: 20000, n_features: 981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, tokenizer=split2)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "    \n",
    "    \n",
    "duration = time() - t0\n",
    "\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the test data using the same vectorizer\n",
      "done in 0.208551s at 0.293MB/s\n",
      "n_samples: 1017, n_features: 981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(X_test)\n",
    "duration = time() - t0\n",
    "\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model/ads-detect-1-20200125.emb', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_support(indices=False)\n",
    "# Get a mask, or integer index, of the features selected\n",
    "#\n",
    "# indicesbool, default=False\n",
    "# If True, the return value will be an array of integers, rather than a boolean mask.\n",
    "\n",
    "if opts.select_chi2:\n",
    "    print(\"Extracting %d best features by a chi-squared test\" % opts.select_chi2)\n",
    "    \n",
    "    t0 = time()\n",
    "    \n",
    "    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
    "    X_train = ch2.fit_transform(X_train, y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    \n",
    "    if feature_names: feature_names = [feature_names[i] for i in ch2.get_support(indices=True)]\n",
    "        \n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_names: feature_names = np.asarray(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(clf, X_train, y_train):\n",
    "    \n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "    \n",
    "    return train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(clf, X_test):\n",
    "    \n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "    \n",
    "    return pred, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, pred):\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_coef(clf, opts, feature_names):\n",
    "    # TODO:\n",
    "    \n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if opts.print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            \n",
    "            #for i, label in enumerate(target_names):\n",
    "              #  top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                #print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(opts, y_test, pred):\n",
    "    \n",
    "    if opts.print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(opts, y_test, pred):\n",
    "    \n",
    "    if opts.print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc(clf):\n",
    "    return str(clf).split('(')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __benchmark(X_train, y_train, X_test, y_test, opts, feature_names, clf):\n",
    "    \n",
    "    train_time = fit(clf, X_train, y_train)\n",
    "    pred, test_time = predict(clf, X_test)\n",
    "    score = accuracy(y_test, pred)\n",
    "    clf_descr = get_desc(clf)\n",
    "\n",
    "    print_coef(clf, opts, feature_names)\n",
    "    print_report(opts, y_test, pred)\n",
    "    print_cm(opts, y_test, pred)\n",
    "    print()\n",
    "    \n",
    "    return pred, clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = partial(__benchmark, X_train, y_train, X_test, y_test, opts, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(solver='sag', tol=0.01)\n",
      "train time: 0.080s\n",
      "test time:  0.001s\n",
      "accuracy:   0.925\n",
      "dimensionality: 981\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.80      0.87       313\n",
      "           1       0.92      0.98      0.95       704\n",
      "\n",
      "    accuracy                           0.93      1017\n",
      "   macro avg       0.93      0.89      0.91      1017\n",
      "weighted avg       0.93      0.93      0.92      1017\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(max_iter=50)\n",
      "train time: 0.017s\n",
      "test time:  0.001s\n",
      "accuracy:   0.918\n",
      "dimensionality: 981\n",
      "density: 0.963303\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.88      0.87       313\n",
      "           1       0.95      0.94      0.94       704\n",
      "\n",
      "    accuracy                           0.92      1017\n",
      "   macro avg       0.90      0.91      0.90      1017\n",
      "weighted avg       0.92      0.92      0.92      1017\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(max_iter=50)\n",
      "train time: 0.030s\n",
      "test time:  0.001s\n",
      "accuracy:   0.938\n",
      "dimensionality: 981\n",
      "density: 0.997961\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.88      0.90       313\n",
      "           1       0.95      0.97      0.96       704\n",
      "\n",
      "    accuracy                           0.94      1017\n",
      "   macro avg       0.93      0.92      0.93      1017\n",
      "weighted avg       0.94      0.94      0.94      1017\n",
      "\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(n_neighbors=10)\n",
      "train time: 0.003s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyh/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:555: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.666s\n",
      "accuracy:   0.899\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.77      0.82       313\n",
      "           1       0.90      0.96      0.93       704\n",
      "\n",
      "    accuracy                           0.90      1017\n",
      "   macro avg       0.89      0.86      0.88      1017\n",
      "weighted avg       0.90      0.90      0.90      1017\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier()\n",
      "train time: 5.950s\n",
      "test time:  0.039s\n",
      "accuracy:   0.939\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.85      0.90       313\n",
      "           1       0.94      0.98      0.96       704\n",
      "\n",
      "    accuracy                           0.94      1017\n",
      "   macro avg       0.94      0.91      0.93      1017\n",
      "weighted avg       0.94      0.94      0.94      1017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(max_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(max_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(dual=False, tol=0.001)\n",
      "train time: 0.044s\n",
      "test time:  0.001s\n",
      "accuracy:   0.945\n",
      "dimensionality: 981\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.87      0.91       313\n",
      "           1       0.95      0.98      0.96       704\n",
      "\n",
      "    accuracy                           0.94      1017\n",
      "   macro avg       0.94      0.92      0.93      1017\n",
      "weighted avg       0.94      0.94      0.94      1017\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50)\n",
      "train time: 0.019s\n",
      "test time:  0.001s\n",
      "accuracy:   0.942\n",
      "dimensionality: 981\n",
      "density: 0.985729\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.85      0.90       313\n",
      "           1       0.94      0.98      0.96       704\n",
      "\n",
      "    accuracy                           0.94      1017\n",
      "   macro avg       0.95      0.92      0.93      1017\n",
      "weighted avg       0.94      0.94      0.94      1017\n",
      "\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(dual=False, penalty='l1', tol=0.001)\n",
      "train time: 0.308s\n",
      "test time:  0.000s\n",
      "accuracy:   0.938\n",
      "dimensionality: 981\n",
      "density: 0.541284\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.87      0.90       313\n",
      "           1       0.94      0.97      0.96       704\n",
      "\n",
      "    accuracy                           0.94      1017\n",
      "   macro avg       0.94      0.92      0.93      1017\n",
      "weighted avg       0.94      0.94      0.94      1017\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50, penalty='l1')\n",
      "train time: 0.031s\n",
      "test time:  0.000s\n",
      "accuracy:   0.919\n",
      "dimensionality: 981\n",
      "density: 0.214067\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.81      0.86       313\n",
      "           1       0.92      0.97      0.94       704\n",
      "\n",
      "    accuracy                           0.92      1017\n",
      "   macro avg       0.92      0.89      0.90      1017\n",
      "weighted avg       0.92      0.92      0.92      1017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50, penalty=penalty)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50, penalty='elasticnet')\n",
      "train time: 0.034s\n",
      "test time:  0.000s\n",
      "accuracy:   0.939\n",
      "dimensionality: 981\n",
      "density: 0.661570\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.84      0.89       313\n",
      "           1       0.93      0.98      0.96       704\n",
      "\n",
      "    accuracy                           0.94      1017\n",
      "   macro avg       0.94      0.91      0.93      1017\n",
      "weighted avg       0.94      0.94      0.94      1017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50, penalty=\"elasticnet\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid()\n",
      "train time: 0.006s\n",
      "test time:  0.001s\n",
      "accuracy:   0.857\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.73      0.76       313\n",
      "           1       0.89      0.91      0.90       704\n",
      "\n",
      "    accuracy                           0.86      1017\n",
      "   macro avg       0.84      0.82      0.83      1017\n",
      "weighted avg       0.86      0.86      0.86      1017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01)\n",
      "train time: 0.006s\n",
      "test time:  0.000s\n",
      "accuracy:   0.864\n",
      "dimensionality: 981\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.68      0.76       313\n",
      "           1       0.87      0.94      0.91       704\n",
      "\n",
      "    accuracy                           0.86      1017\n",
      "   macro avg       0.86      0.81      0.83      1017\n",
      "weighted avg       0.86      0.86      0.86      1017\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01)\n",
      "train time: 0.006s\n",
      "test time:  0.001s\n",
      "accuracy:   0.869\n",
      "dimensionality: 981\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.69      0.77       313\n",
      "           1       0.87      0.95      0.91       704\n",
      "\n",
      "    accuracy                           0.87      1017\n",
      "   macro avg       0.86      0.82      0.84      1017\n",
      "weighted avg       0.87      0.87      0.87      1017\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "ComplementNB(alpha=0.1)\n",
      "train time: 0.005s\n",
      "test time:  0.000s\n",
      "accuracy:   0.883\n",
      "dimensionality: 981\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.87      0.82       313\n",
      "           1       0.94      0.89      0.91       704\n",
      "\n",
      "    accuracy                           0.88      1017\n",
      "   macro avg       0.86      0.88      0.87      1017\n",
      "weighted avg       0.89      0.88      0.88      1017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "results.append(benchmark(ComplementNB(alpha=.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(dual=False, penalty='l1',\n",
      "                                                     tol=0.001))),\n",
      "                ('classification', LinearSVC())])\n",
      "train time: 0.374s\n",
      "test time:  0.001s\n",
      "accuracy:   0.948\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.88      0.91       313\n",
      "           1       0.95      0.98      0.96       704\n",
      "\n",
      "    accuracy                           0.95      1017\n",
      "   macro avg       0.95      0.93      0.94      1017\n",
      "weighted avg       0.95      0.95      0.95      1017\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 2**5-1, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'\n",
    "\n",
    "num_round = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 981)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 981)\n",
      "(20000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 982)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = np.expand_dims(data_train['content'].apply(len).to_numpy(), axis=1)\n",
    "print(X_train.shape)\n",
    "print(length.shape)\n",
    "X_train = csr_matrix(np.concatenate((X_train.toarray(), length), axis=1))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1017, 981)\n",
      "(1017, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1017, 982)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = np.expand_dims(data_test['content'].apply(len).to_numpy(), axis=1)\n",
    "print(X_test.shape)\n",
    "print(length.shape)\n",
    "X_test = csr_matrix(np.concatenate((X_test.toarray(), length), axis=1))\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16100, number of negative: 3900\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 50997\n",
      "[LightGBM] [Info] Number of data points in the train set: 20000, number of used features: 982\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.805000 -> initscore=1.417843\n",
      "[LightGBM] [Info] Start training from score 1.417843\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "bst = lgb.train(param, train_data, num_round)\n",
    "\n",
    "y_pred = bst.predict(X_test)\n",
    "y_pred = np.where(y_pred > 0.5, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.89      0.93       313\n",
      "           1       0.95      0.99      0.97       704\n",
      "\n",
      "    accuracy                           0.96      1017\n",
      "   macro avg       0.96      0.94      0.95      1017\n",
      "weighted avg       0.96      0.96      0.96      1017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f58492bc5e0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.save_model('./model/ads-detect-1-20200125.mdl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## efficiency"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(5)]\n",
    "\n",
    "preds, clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.title(\"Score\")\n",
    "\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\", color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred, _, _, _, _ = benchmark(ComplementNB(alpha=.1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_pred, _, _, _, _ = benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-2ad776a6ef25>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokens'] = df['content'].apply(split2)\n"
     ]
    }
   ],
   "source": [
    "df = data_test[['label', 'pred', 'content']]\n",
    "df['tokens'] = df['content'].apply(split2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>收个功勋号！</td>\n",
       "      <td>[收, 个, 功, 勋, 号, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>兄弟来新游戏试玩不？人多**好</td>\n",
       "      <td>[兄, 弟, 来, 新, 游, 戏, 试, 玩, 不, 人, 多, 好, &lt;special-char&gt;, &lt;special-char&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>加微信好友。</td>\n",
       "      <td>[+, 微, 好, 友, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>嫁一下**徽信xsw767拉你进群，领取礼包大家一起玩</td>\n",
       "      <td>[+, 微, &lt;contact&gt;, 拉, 进, 群, ,, 领, 取, 礼, 包, 大, 家, 一, 起, 玩, &lt;special-char&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>你那还有礼包码吗</td>\n",
       "      <td>[还, 有, 礼, 包, 码]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>你打公告我打资源号位置</td>\n",
       "      <td>[打, 公, 告, 打, 资, 源, 号, 位, 置]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>我下装备你过来，不行再下将</td>\n",
       "      <td>[下, 装, 备, 过, 来, ,, 不, 行, 再, 下, 将]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>战力9-12万v1想刷军功的私聊我</td>\n",
       "      <td>[战, 力, &lt;num-3&gt;, 万, 微, &lt;contact&gt;, 想, 刷, 军, 功, 私, 聊, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>不是，我说的让你们看看要不要资源</td>\n",
       "      <td>[不, 是, ,, 说, 让, 看, 看, 要, 不, 要, 资, 源]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>招手游代理或兼职，拥有个人代理后台，周结算，0加盟费，合作即可签合同，公司扶持，想了解的可以咨询我。</td>\n",
       "      <td>[招, 手, 游, 代, 理, 或, &lt;unk&gt;, &lt;unk&gt;, ,, &lt;unk&gt;, 有, 个, 人, 代, 理, 后, 台, ,, &lt;unk&gt;, 结, 算, ,, &lt;num-1&gt;, +, 盟, 费, ,, 作, 即, 可, &lt;unk&gt;, 同, ,, 公, 司, &lt;unk&gt;, 持, ,, 想, 解, 可, 以, &lt;unk&gt;, &lt;unk&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>招手游代理兼职，无需加盟费，**后台，合同模式，公司扶持政策，想了解的可以私聊我</td>\n",
       "      <td>[招, 手, 游, 代, 理, &lt;unk&gt;, &lt;unk&gt;, ,, 无, 需, +, 盟, 费, ,, 后, 台, ,, 同, &lt;unk&gt;, &lt;unk&gt;, ,, 公, 司, &lt;unk&gt;, 持, 政, 策, ,, 想, 解, 可, 以, 私, 聊, &lt;special-char&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>出号！一红，三的卢</td>\n",
       "      <td>[出, 号, 一, 红, ,, 三, &lt;unk&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>开仓吃饭了，威z506420409</td>\n",
       "      <td>[开, 仓, 吃, 饭, ,, 微, &lt;contact&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>「开仓吃饭」「{localization:189-393}，88965」</td>\n",
       "      <td>[开, 仓, 吃, 饭, &lt;loc&gt;, ,, &lt;num-5&gt;, &lt;special-char&gt;, &lt;special-char&gt;, &lt;special-char&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>出h吗</td>\n",
       "      <td>[出, h]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>看公告进群拿礼包和攻略啊</td>\n",
       "      <td>[看, 公, 告, 进, 群, 拿, 礼, 包, 和, 攻, 略]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>为实现该产品大力推广，从现在开始截止到12月7号凡是只要购买此任何一个（产品就送至尊月卡12个月包括任何一匹红马只限一匹和一套红马具）快来订购吧。</td>\n",
       "      <td>[为, 实, 现, 该, &lt;unk&gt;, 品, 大, 力, 推, 广, ,, 从, 现, 在, 开, 始, 截, 止, 到, &lt;num-2&gt;, 月, &lt;num-1&gt;, 号, &lt;unk&gt;, 是, 只, 要, 购, 买, 此, 任, 何, 一, 个, &lt;unk&gt;, 品, 送, 至, 尊, 月, 卡, &lt;num-2&gt;, 个, 月, 包, &lt;unk&gt;, 任, 何, 一, 匹, 红, 马, 只, 限, 一, 匹, 和, 一, 套, 红, 马, 具, 快, 来, &lt;unk&gt;, 购, &lt;special-char&gt;, &lt;special-char&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>朋友，就差你还没伽老大了，老大\\/X：1505080401 谢谢配合</td>\n",
       "      <td>[朋, 友, ,, 差, 还, &lt;unk&gt;, 老, 大, ,, 老, 大, &lt;contact&gt;, &lt;special-char&gt;, &lt;special-char&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>出h嘛</td>\n",
       "      <td>[出, h]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>开仓 {localization:189-393}，88965</td>\n",
       "      <td>[开, 仓, &lt;loc&gt;, ,, &lt;num-5&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>你好，你这个号打算卖吗？</td>\n",
       "      <td>[好, ,, 这, 个, 号, 打, 算, 卖, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>你好，你这个号打算卖吗</td>\n",
       "      <td>[好, ,, 这, 个, 号, 打, 算, 卖]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>晚上要打城吗？不打我要买资源了</td>\n",
       "      <td>[晚, 上, 要, 打, 城, 不, 打, 要, 买, 资, 源, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>推荐大家两个网络书作者，高月和六如和尚，他俩的架空文推荐大家看一看，写的很好。</td>\n",
       "      <td>[推, &lt;unk&gt;, 大, 家, 两, 个, &lt;unk&gt;, &lt;unk&gt;, 书, 作, 者, ,, 高, 月, 和, 六, 如, 和, &lt;unk&gt;, ,, 俩, +, 空, 文, 推, &lt;unk&gt;, 大, 家, 看, 一, 看, ,, &lt;unk&gt;, 很, 好, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>10=4e,负重200</td>\n",
       "      <td>[&lt;contact&gt;, ,, 负, 重, &lt;num-3&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>你号给我吧</td>\n",
       "      <td>[号, 给]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>加你好友好吗</td>\n",
       "      <td>[+, 好, 友, 好]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>关羽张辽孙策吕布免领+q：2043603184，更有五个**码</td>\n",
       "      <td>[关, 羽, 张, &lt;unk&gt;, 孙, 策, &lt;unk&gt;, 布, 免, 领, +, &lt;contact&gt;, ,, 更, 有, 五, 个, 码, &lt;special-char&gt;, &lt;special-char&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>没有领到648充值卡的兄弟抓紧了，每天都有发，名额有限，+V：LGC44055,先到先得</td>\n",
       "      <td>[有, 领, 到, &lt;num-3&gt;, 充, 值, 卡, 兄, 弟, &lt;unk&gt;, 紧, ,, 每, 天, 都, 有, 发, ,, 名, &lt;unk&gt;, 有, 限, ,, +, &lt;contact&gt;, ,, 先, 到, 先, 得, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>帝国元首，几块钱的资源都买不起吗？曾经还是团友呢，真是高看你</td>\n",
       "      <td>[帝, 国, 元, 首, ,, 几, 块, 钱, 资, 源, 都, 买, 不, 起, &lt;unk&gt;, 经, 还, 是, 团, 友, ,, 真, 是, 高, 看, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>常玩的兄弟茄徵新ＳＬＲ８８２没加的一律当机器人提掉，来群换图集貂蝉，送花送金币</td>\n",
       "      <td>[常, 玩, 兄, 弟, +, 微, &lt;contact&gt;, +, 一, &lt;unk&gt;, 当, 机, 器, 人, 提, 掉, ,, 来, 群, 换, 图, 集, &lt;unk&gt;, &lt;unk&gt;, ,, 送, 花, 送, 金, 币]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>大家都加一下**微信 lf036x 进讨论组 拿礼包码 和300w的粮* ，大家一起玩。差你没进讨论组了，在不加踢</td>\n",
       "      <td>[大, 家, 都, +, 微, &lt;contact&gt;, 进, 讨, 论, 组, 拿, 礼, 包, 码, 和, &lt;contact&gt;, &lt;unk&gt;, ,, 大, 家, 一, 起, 玩, 差, 进, 讨, 论, 组, ,, 在, 不, +, 踢, &lt;special-char&gt;, &lt;special-char&gt;, &lt;special-char&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>你好 你这个号打算卖吗</td>\n",
       "      <td>[好, 这, 个, 号, 打, 算, 卖]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pred  \\\n",
       "61       -1     1   \n",
       "122      -1     1   \n",
       "128      -1     1   \n",
       "237      -1     1   \n",
       "241      -1     1   \n",
       "244      -1     1   \n",
       "250      -1     1   \n",
       "258      -1     1   \n",
       "264      -1     1   \n",
       "314      -1     1   \n",
       "317      -1     1   \n",
       "325      -1     1   \n",
       "387      -1     1   \n",
       "392      -1     1   \n",
       "394      -1     1   \n",
       "502      -1     1   \n",
       "533      -1     1   \n",
       "550      -1     1   \n",
       "552      -1     1   \n",
       "597      -1     1   \n",
       "627      -1     1   \n",
       "679      -1     1   \n",
       "687      -1     1   \n",
       "726      -1     1   \n",
       "922      -1     1   \n",
       "928      -1     1   \n",
       "934      -1     1   \n",
       "936      -1     1   \n",
       "944      -1     1   \n",
       "960      -1     1   \n",
       "987      -1     1   \n",
       "990      -1     1   \n",
       "1005     -1     1   \n",
       "\n",
       "                                                                        content  \\\n",
       "61                                                                       收个功勋号！   \n",
       "122                                                             兄弟来新游戏试玩不？人多**好   \n",
       "128                                                                      加微信好友。   \n",
       "237                                                 嫁一下**徽信xsw767拉你进群，领取礼包大家一起玩   \n",
       "241                                                                    你那还有礼包码吗   \n",
       "244                                                                 你打公告我打资源号位置   \n",
       "250                                                               我下装备你过来，不行再下将   \n",
       "258                                                           战力9-12万v1想刷军功的私聊我   \n",
       "264                                                            不是，我说的让你们看看要不要资源   \n",
       "314                          招手游代理或兼职，拥有个人代理后台，周结算，0加盟费，合作即可签合同，公司扶持，想了解的可以咨询我。   \n",
       "317                                    招手游代理兼职，无需加盟费，**后台，合同模式，公司扶持政策，想了解的可以私聊我   \n",
       "325                                                                   出号！一红，三的卢   \n",
       "387                                                           开仓吃饭了，威z506420409   \n",
       "392                                        「开仓吃饭」「{localization:189-393}，88965」   \n",
       "394                                                                         出h吗   \n",
       "502                                                                看公告进群拿礼包和攻略啊   \n",
       "533   为实现该产品大力推广，从现在开始截止到12月7号凡是只要购买此任何一个（产品就送至尊月卡12个月包括任何一匹红马只限一匹和一套红马具）快来订购吧。   \n",
       "550                                          朋友，就差你还没伽老大了，老大\\/X：1505080401 谢谢配合   \n",
       "552                                                                         出h嘛   \n",
       "597                                             开仓 {localization:189-393}，88965   \n",
       "627                                                                你好，你这个号打算卖吗？   \n",
       "679                                                                 你好，你这个号打算卖吗   \n",
       "687                                                             晚上要打城吗？不打我要买资源了   \n",
       "726                                     推荐大家两个网络书作者，高月和六如和尚，他俩的架空文推荐大家看一看，写的很好。   \n",
       "922                                                                 10=4e,负重200   \n",
       "928                                                                       你号给我吧   \n",
       "934                                                                      加你好友好吗   \n",
       "936                                             关羽张辽孙策吕布免领+q：2043603184，更有五个**码   \n",
       "944                                没有领到648充值卡的兄弟抓紧了，每天都有发，名额有限，+V：LGC44055,先到先得   \n",
       "960                                              帝国元首，几块钱的资源都买不起吗？曾经还是团友呢，真是高看你   \n",
       "987                                     常玩的兄弟茄徵新ＳＬＲ８８２没加的一律当机器人提掉，来群换图集貂蝉，送花送金币   \n",
       "990                   大家都加一下**微信 lf036x 进讨论组 拿礼包码 和300w的粮* ，大家一起玩。差你没进讨论组了，在不加踢   \n",
       "1005                                                                你好 你这个号打算卖吗   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                            tokens  \n",
       "61                                                                                                                                                                                                                                                                 [收, 个, 功, 勋, 号, <special-char>]  \n",
       "122                                                                                                                                                                                                           [兄, 弟, 来, 新, 游, 戏, 试, 玩, 不, 人, 多, 好, <special-char>, <special-char>, <special-char>]  \n",
       "128                                                                                                                                                                                                                                                                   [+, 微, 好, 友, <special-char>]  \n",
       "237                                                                                                                                                                                                       [+, 微, <contact>, 拉, 进, 群, ,, 领, 取, 礼, 包, 大, 家, 一, 起, 玩, <special-char>, <special-char>]  \n",
       "241                                                                                                                                                                                                                                                                                [还, 有, 礼, 包, 码]  \n",
       "244                                                                                                                                                                                                                                                                    [打, 公, 告, 打, 资, 源, 号, 位, 置]  \n",
       "250                                                                                                                                                                                                                                                              [下, 装, 备, 过, 来, ,, 不, 行, 再, 下, 将]  \n",
       "258                                                                                                                                                                                                                             [战, 力, <num-3>, 万, 微, <contact>, 想, 刷, 军, 功, 私, 聊, <special-char>]  \n",
       "264                                                                                                                                                                                                                                                           [不, 是, ,, 说, 让, 看, 看, 要, 不, 要, 资, 源]  \n",
       "314                                                                                                     [招, 手, 游, 代, 理, 或, <unk>, <unk>, ,, <unk>, 有, 个, 人, 代, 理, 后, 台, ,, <unk>, 结, 算, ,, <num-1>, +, 盟, 费, ,, 作, 即, 可, <unk>, 同, ,, 公, 司, <unk>, 持, ,, 想, 解, 可, 以, <unk>, <unk>, <special-char>]  \n",
       "317                                                                                                                                     [招, 手, 游, 代, 理, <unk>, <unk>, ,, 无, 需, +, 盟, 费, ,, 后, 台, ,, 同, <unk>, <unk>, ,, 公, 司, <unk>, 持, 政, 策, ,, 想, 解, 可, 以, 私, 聊, <special-char>, <special-char>]  \n",
       "325                                                                                                                                                                                                                                                      [出, 号, 一, 红, ,, 三, <unk>, <special-char>]  \n",
       "387                                                                                                                                                                                                                                                                  [开, 仓, 吃, 饭, ,, 微, <contact>]  \n",
       "392                                                                                                                                                                                                [开, 仓, 吃, 饭, <loc>, ,, <num-5>, <special-char>, <special-char>, <special-char>, <special-char>]  \n",
       "394                                                                                                                                                                                                                                                                                         [出, h]  \n",
       "502                                                                                                                                                                                                                                                              [看, 公, 告, 进, 群, 拿, 礼, 包, 和, 攻, 略]  \n",
       "533   [为, 实, 现, 该, <unk>, 品, 大, 力, 推, 广, ,, 从, 现, 在, 开, 始, 截, 止, 到, <num-2>, 月, <num-1>, 号, <unk>, 是, 只, 要, 购, 买, 此, 任, 何, 一, 个, <unk>, 品, 送, 至, 尊, 月, 卡, <num-2>, 个, 月, 包, <unk>, 任, 何, 一, 匹, 红, 马, 只, 限, 一, 匹, 和, 一, 套, 红, 马, 具, 快, 来, <unk>, 购, <special-char>, <special-char>, <special-char>]  \n",
       "550                                                                                                                                                                                               [朋, 友, ,, 差, 还, <unk>, 老, 大, ,, 老, 大, <contact>, <special-char>, <special-char>, <special-char>]  \n",
       "552                                                                                                                                                                                                                                                                                         [出, h]  \n",
       "597                                                                                                                                                                                                                                                                      [开, 仓, <loc>, ,, <num-5>]  \n",
       "627                                                                                                                                                                                                                                                       [好, ,, 这, 个, 号, 打, 算, 卖, <special-char>]  \n",
       "679                                                                                                                                                                                                                                                                       [好, ,, 这, 个, 号, 打, 算, 卖]  \n",
       "687                                                                                                                                                                                                                                              [晚, 上, 要, 打, 城, 不, 打, 要, 买, 资, 源, <special-char>]  \n",
       "726                                                                                                                                              [推, <unk>, 大, 家, 两, 个, <unk>, <unk>, 书, 作, 者, ,, 高, 月, 和, 六, 如, 和, <unk>, ,, 俩, +, 空, 文, 推, <unk>, 大, 家, 看, 一, 看, ,, <unk>, 很, 好, <special-char>]  \n",
       "922                                                                                                                                                                                                                                                  [<contact>, ,, 负, 重, <num-3>, <special-char>]  \n",
       "928                                                                                                                                                                                                                                                                                         [号, 给]  \n",
       "934                                                                                                                                                                                                                                                                                   [+, 好, 友, 好]  \n",
       "936                                                                                                                                                                         [关, 羽, 张, <unk>, 孙, 策, <unk>, 布, 免, 领, +, <contact>, ,, 更, 有, 五, 个, 码, <special-char>, <special-char>, <special-char>]  \n",
       "944                                                                                                                                                               [有, 领, 到, <num-3>, 充, 值, 卡, 兄, 弟, <unk>, 紧, ,, 每, 天, 都, 有, 发, ,, 名, <unk>, 有, 限, ,, +, <contact>, ,, 先, 到, 先, 得, <special-char>]  \n",
       "960                                                                                                                                                                                                [帝, 国, 元, 首, ,, 几, 块, 钱, 资, 源, 都, 买, 不, 起, <unk>, 经, 还, 是, 团, 友, ,, 真, 是, 高, 看, <special-char>]  \n",
       "987                                                                                                                                                                                 [常, 玩, 兄, 弟, +, 微, <contact>, +, 一, <unk>, 当, 机, 器, 人, 提, 掉, ,, 来, 群, 换, 图, 集, <unk>, <unk>, ,, 送, 花, 送, 金, 币]  \n",
       "990                                                                                                        [大, 家, 都, +, 微, <contact>, 进, 讨, 论, 组, 拿, 礼, 包, 码, 和, <contact>, <unk>, ,, 大, 家, 一, 起, 玩, 差, 进, 讨, 论, 组, ,, 在, 不, +, 踢, <special-char>, <special-char>, <special-char>, <special-char>]  \n",
       "1005                                                                                                                                                                                                                                                                         [好, 这, 个, 号, 打, 算, 卖]  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[(~(df.label==df.pred)) & (df.label==-1)]\n",
    "print(df1.shape)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>霸服军团收吴，魏，蜀国活人，来的加 1979574312私聊</td>\n",
       "      <td>[霸, 服, &lt;corpus&gt;, 收, 吴, ,, 魏, ,, 蜀, 国, 人, ,, 来, +, &lt;num-10&gt;, 私, 聊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>新区195收人。，最强吴国军团。加weixin=13288669123</td>\n",
       "      <td>[新, 区, &lt;num-3&gt;, &lt;recruit&gt;, ,, 最, 强, 吴, 国, &lt;corpus&gt;, +, &lt;contact&gt;, &lt;special-char&gt;, &lt;special-char&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>能告诉我 开区啥价格 现在啥价格么</td>\n",
       "      <td>[能, 告, 诉, 开, 区, 啥, 价, 格, 现, 在, 啥, 价, 格]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>军团要整顿，加我微信，我拉你进核心群：571773352</td>\n",
       "      <td>[&lt;corpus&gt;, 要, 整, &lt;unk&gt;, ,, +, 微, ,, 拉, 进, &lt;unk&gt;, 心, 群, &lt;num-9&gt;, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>兄弟在吗？我是灰长小号，十下我徽KLDY0855，进交流裙，没十的一会当机器人T了</td>\n",
       "      <td>[兄, 弟, 在, 是, &lt;unk&gt;, 长, 小, 号, ,, +, 微, &lt;contact&gt;, ,, 进, 交, 流, 裙, ,, +, 一, 会, 当, 机, 器, 人, t, &lt;special-char&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>没有微信号了，你那有吗</td>\n",
       "      <td>[有, 微, 号, ,, 有]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>酒馆收活人，来的私聊</td>\n",
       "      <td>[酒, &lt;unk&gt;, &lt;recruit&gt;, ,, 来, 私, 聊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>资源号</td>\n",
       "      <td>[资, 源, 号]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  pred                                    content  \\\n",
       "99       1    -1             霸服军团收吴，魏，蜀国活人，来的加 1979574312私聊   \n",
       "100      1    -1        新区195收人。，最强吴国军团。加weixin=13288669123   \n",
       "211      1    -1                          能告诉我 开区啥价格 现在啥价格么   \n",
       "454      1    -1               军团要整顿，加我微信，我拉你进核心群：571773352   \n",
       "513      1    -1  兄弟在吗？我是灰长小号，十下我徽KLDY0855，进交流裙，没十的一会当机器人T了   \n",
       "519      1    -1                                没有微信号了，你那有吗   \n",
       "689      1    -1                                 酒馆收活人，来的私聊   \n",
       "848      1    -1                                        资源号   \n",
       "\n",
       "                                                                                                                tokens  \n",
       "99                                                   [霸, 服, <corpus>, 收, 吴, ,, 魏, ,, 蜀, 国, 人, ,, 来, +, <num-10>, 私, 聊]  \n",
       "100  [新, 区, <num-3>, <recruit>, ,, 最, 强, 吴, 国, <corpus>, +, <contact>, <special-char>, <special-char>, <special-char>]  \n",
       "211                                                                            [能, 告, 诉, 开, 区, 啥, 价, 格, 现, 在, 啥, 价, 格]  \n",
       "454                                    [<corpus>, 要, 整, <unk>, ,, +, 微, ,, 拉, 进, <unk>, 心, 群, <num-9>, <special-char>]  \n",
       "513         [兄, 弟, 在, 是, <unk>, 长, 小, 号, ,, +, 微, <contact>, ,, 进, 交, 流, 裙, ,, +, 一, 会, 当, 机, 器, 人, t, <special-char>]  \n",
       "519                                                                                                    [有, 微, 号, ,, 有]  \n",
       "689                                                                                  [酒, <unk>, <recruit>, ,, 来, 私, 聊]  \n",
       "848                                                                                                          [资, 源, 号]  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[(~(df.label==df.pred)) & (df.label==1)]\n",
    "print(df2.shape)\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
