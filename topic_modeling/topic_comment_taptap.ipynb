{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import jieba\n",
    "import joblib\n",
    "import string\n",
    "import codecs\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "#import matplotlib as mpl\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from scipy.cluster.hierarchy import ward\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data'\n",
    "# filename = 'comment.taptap.sgz2017-20210127-1-labeled.csv'\n",
    "filename = 'comment.taptap-20210127-1.csv'\n",
    "df = pd.read_csv(os.path.join(path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.game=='率土之滨']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1816, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>率土之滨</td>\n",
       "      <td>1.s赛季节奏越来越快，氪金体验太好了，可惜氪不动了，慢慢跟不上现在高战氪金要求了,2.出卡...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      game                                               text\n",
       "9562  率土之滨  1.s赛季节奏越来越快，氪金体验太好了，可惜氪不动了，慢慢跟不上现在高战氪金要求了,2.出卡..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    s = s.lower()\n",
    "    s = unicodedata.normalize('NFKC', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [normalize(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seq(s):\n",
    "    return re.split(r'[,，.。?!]+', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [to_seq(text) for text in texts]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(chain.from_iterable(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 28 ms, total: 1.14 s\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%time texts = [jieba.lcut(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_stopwords(path):\n",
    "    stopwords = []\n",
    "    for filename in os.listdir(path):\n",
    "        with open(os.path.join(path, filename), 'r') as f:\n",
    "            stopwords.extend([w.strip() for w in f.readlines()])            \n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stopwords = get_stopwords('/home/wangyh/project/document_cluster/dicts/')\n",
    "print(len(stopwords))\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time texts = [[word for word in text if word not in stopwords] for text in texts]\n",
    "print(len(texts[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%time texts = [[word for word in text if 1 < len(word)] for text in texts]\n",
    "print(len(texts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19689"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.125, \n",
    "    max_features=200000,\n",
    "    min_df=0.01, \n",
    "    # stop_words='english',\n",
    "    use_idf=True, \n",
    "    # tokenizer=jieba.lcut, \n",
    "    # ngram_range=(1,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 136 ms, sys: 0 ns, total: 136 ms\n",
      "Wall time: 135 ms\n"
     ]
    }
   ],
   "source": [
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(map(lambda t: ' '.join(t), texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19689, 26)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-dim distance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-dim"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MDS()\n",
    "\n",
    "# two components as we're plotting points in a two-dimensional plane\n",
    "# \"precomputed\" because we provide a distance matrix\n",
    "# we will also specify `random_state` so the plot is reproducible.\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=random_state, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# shape = (n_samples, n_components)\n",
    "%time pos = mds.fit_transform(dist)\n",
    "pos.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xs, ys = pos[:, 0], pos[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: may be need normalize/scaling before clustering\n",
    "km = KMeans(n_clusters=num_clusters, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 408 ms, total: 10.5 s\n",
      "Wall time: 1.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=40, random_state=42)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time km.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19689"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19689"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(km.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## latent dirichlet allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 16s, sys: 584 ms, total: 10min 16s\n",
      "Wall time: 10min 15s\n",
      "[(0, 0.012500032), (1, 0.012500032), (2, 0.012500032), (3, 0.012500032), (4, 0.012500032), (5, 0.5124988), (6, 0.012500032), (7, 0.012500032), (8, 0.012500032), (9, 0.012500032), (10, 0.012500032), (11, 0.012500032), (12, 0.012500032), (13, 0.012500032), (14, 0.012500032), (15, 0.012500032), (16, 0.012500032), (17, 0.012500032), (18, 0.012500032), (19, 0.012500032), (20, 0.012500032), (21, 0.012500032), (22, 0.012500032), (23, 0.012500032), (24, 0.012500032), (25, 0.012500032), (26, 0.012500032), (27, 0.012500032), (28, 0.012500032), (29, 0.012500032), (30, 0.012500032), (31, 0.012500032), (32, 0.012500032), (33, 0.012500032), (34, 0.012500032), (35, 0.012500032), (36, 0.012500032), (37, 0.012500032), (38, 0.012500032), (39, 0.012500032)]\n"
     ]
    }
   ],
   "source": [
    "%time lda = models.LdaModel(corpus, \\\n",
    "                            num_topics=num_clusters, \\\n",
    "                            id2word=dictionary, \\\n",
    "                            update_every=5, \\\n",
    "                            chunksize=10000, \\\n",
    "                            passes=100, \\\n",
    "                            random_state=random_state)\n",
    "\n",
    "print(lda[corpus[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(28,\n",
       "  [('没有', 0.15500683),\n",
       "   ('什么', 0.100864895),\n",
       "   ('都', 0.04893336),\n",
       "   ('了', 0.043656353),\n",
       "   ('一次', 0.024116391),\n",
       "   ('一定', 0.0207657),\n",
       "   ('刘备', 0.019426854),\n",
       "   ('武将', 0.019101677),\n",
       "   ('一个', 0.019079909),\n",
       "   ('就', 0.018692683),\n",
       "   ('连', 0.014489682),\n",
       "   ('可是', 0.0144046275),\n",
       "   ('送', 0.014333076),\n",
       "   ('打开', 0.009671928),\n",
       "   ('弄', 0.008652052),\n",
       "   ('五', 0.008449307),\n",
       "   ('吕蒙', 0.007013277),\n",
       "   ('我', 0.0065737986),\n",
       "   ('张', 0.00639404),\n",
       "   ('弃游', 0.0060341824)])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_matrix = lda.show_topics(formatted=False, num_words=20)\n",
    "topics_matrix[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_topics(i, k, cluster_centers_, terms):\n",
    "    order_centroids = cluster_centers_.argsort()[:, ::-1]\n",
    "    return [terms[ind].encode().decode('utf-8', 'ignore') for ind in order_centroids[i, :k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_names(k, cluster_centers_, terms):\n",
    "    return [','.join(cluster_topics(i, k, cluster_centers_, terms)) for i in range(len(cluster_centers_))]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def cluster_info(i, df, info):\n",
    "    return df[df['cluster']==i][info].values.tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def pprint(num_clusters, cluster_centers_, terms, df, k):\n",
    "\n",
    "    print(\"Top terms per cluster:\")\n",
    "    print()\n",
    "\n",
    "    for i in range(num_clusters):\n",
    "\n",
    "        \"\"\" term import -> term vector\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Cluster %d words:\" % i, end='')\n",
    "        \n",
    "        for token in cluster_topics(i, k, cluster_centers_, terms):\n",
    "            print(token, end=',')\n",
    "\n",
    "        print()\n",
    "        # print()\n",
    "\n",
    "        \"\"\" cluster id -> title\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"cluster %d text:\" % i)\n",
    "        \n",
    "        for i, title in enumerate(cluster_info(i, df, 'text')[:k]):\n",
    "            # print(' %s,' % title, end='')\n",
    "            print('[%s] %s' % (i, title))\n",
    "\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def report_pprint(df, clusters, terms, cluster_centers_, num_clusters, k):\n",
    "    \"\"\"\n",
    "    Parameter\n",
    "    --------\n",
    "    df : pd.DataFrame, shape=(n_samples, n_dim)\n",
    "        \n",
    "    clusters : list\n",
    "    \n",
    "    terms : vector feature name\n",
    "    \n",
    "    cluster_centers_ : np.array, shape=(n_clusters, n_terms)\n",
    "    \n",
    "    num_clusters : int\n",
    "    \"\"\"\n",
    "    \n",
    "    # add cluster info\n",
    "    df['cluster'] = clusters\n",
    "    print(df['cluster'].value_counts())\n",
    "    \n",
    "    # top tokens\n",
    "    print(len(terms))\n",
    "    print(cluster_centers_.shape)\n",
    "    \n",
    "    pprint(num_clusters, cluster_centers_, terms, df, k)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def visualizing(df_cluster):\n",
    "    # df_cluster = df_cluster.astype({'label': 'int'}).astype({'label': 'str'})\n",
    "    fig = px.scatter(df_cluster, x='x', y='y', color='label', hover_data=['text'])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def report_visualizing(xs, ys, clusters, cluster_names, df):\n",
    "    df_cluster = pd.DataFrame(dict(x=xs, y=ys, label=[cluster_names[c] for c in clusters]))\n",
    "    df_cluster['text'] = df['text'].apply(lambda x: x[:5])\n",
    "    \n",
    "    # print(df_cluster.shape)\n",
    "    # print(df_cluster.head(1))\n",
    "\n",
    "    visualizing(df_cluster)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def report(df, clusters, terms, cluster_centers_, num_clusters, xs, ys, cluster_names, k):\n",
    "    report_pprint(df, clusters, terms, cluster_centers_, num_clusters, k)\n",
    "    report_visualizing(xs, ys, clusters, cluster_names, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['这个,还是,不是,五星,什么,但是,可以,因为,大佬,宝物',\n",
       " '游戏,就是,网易,真的,宝物,什么,系统,赛季,因为,率土',\n",
       " '玩家,宝物,就是,赛季,还是,战法,武将,游戏,不是,五星',\n",
       " '现在,赛季,游戏,宝物,就是,玩家,一个,这个,系统,真的',\n",
       " '没有,宝物,玩家,这个,赛季,还是,战法,就是,不是,五星',\n",
       " '赛季,游戏,玩家,宝物,没有,因为,五星,武将,什么,可以',\n",
       " '策划,玩家,就是,游戏,这个,系统,赛季,宝物,一个,真的',\n",
       " '就是,游戏,一个,玩家,赛季,宝物,这个,没有,不是,真的',\n",
       " '系统,宝物,这个,现在,游戏,真的,策划,一个,什么,率土',\n",
       " '率土,游戏,玩家,现在,还是,就是,一个,这个,宝物,可以',\n",
       " '但是,还是,游戏,现在,真的,宝物,这个,可以,玩家,赛季',\n",
       " '一个,游戏,策划,率土,真的,就是,可以,宝物,网易,玩家',\n",
       " '网易,游戏,策划,玩家,现在,一个,可以,这个,没有,宝物',\n",
       " '还是,策划,现在,玩家,网易,这个,可以,赛季,宝物,一个',\n",
       " '真的,游戏,策划,网易,这个,宝物,现在,玩家,一个,系统',\n",
       " '自己,游戏,玩家,就是,可以,还是,什么,现在,没有,赛季',\n",
       " '平民,玩家,大佬,一个,可以,宝物,游戏,真的,系统,赛季',\n",
       " '武将,宝物,可以,一个,没有,策划,就是,赛季,游戏,这个',\n",
       " '这个,游戏,真的,就是,玩家,可以,策划,率土,赛季,一个',\n",
       " '可以,游戏,玩家,赛季,一个,宝物,没有,现在,策划,这个',\n",
       " '宝物,游戏,可以,平民,大佬,没有,这个,什么,武将,玩家',\n",
       " '因为,游戏,这个,就是,宝物,率土,什么,大佬,玩家,没有',\n",
       " '战法,武将,五星,赛季,可以,就是,但是,什么,一个,游戏',\n",
       " '大佬,就是,赛季,一个,可以,没有,现在,但是,宝物,游戏',\n",
       " '什么,游戏,策划,玩家,网易,宝物,武将,可以,但是,现在',\n",
       " '一个,宝物,不是,大佬,就是,赛季,平民,但是,可以,武将',\n",
       " '不是,游戏,一个,玩家,率土,这个,宝物,大佬,但是,就是',\n",
       " '五星,武将,游戏,就是,真的,现在,一个,赛季,没有,玩家',\n",
       " '系统,一个,赛季,玩家,游戏,平民,不是,五星,什么,但是',\n",
       " '现在,没有,策划,玩家,一个,可以,游戏,但是,真的,就是',\n",
       " '赛季,一个,宝物,五星,游戏,但是,现在,这个,就是,不是',\n",
       " '没有,一个,什么,五星,可以,还是,游戏,大佬,玩家,但是',\n",
       " '平民,大佬,赛季,游戏,宝物,还是,这个,就是,可以,现在',\n",
       " '一个,玩家,游戏,就是,率土,网易,因为,还是,系统,但是',\n",
       " '这个,宝物,赛季,系统,玩家,一个,就是,策划,没有,现在',\n",
       " '玩家,游戏,策划,大佬,什么,真的,但是,不是,宝物,武将',\n",
       " '网易,就是,游戏,系统,还是,现在,宝物,这个,不是,五星',\n",
       " '没有,游戏,这个,可以,率土,玩家,自己,平民,赛季,什么',\n",
       " '还是,游戏,这个,但是,网易,策划,系统,就是,一个,因为',\n",
       " '策划,率土,宝物,但是,平民,还是,网易,一个,系统,玩家']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = km.labels_.tolist()\n",
    "cluster_centers_ = km.cluster_centers_\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "cluster_names = get_cluster_names(k, cluster_centers_, terms)\n",
    "cluster_names"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "report(df, clusters, terms, cluster_centers_, num_clusters, xs, ys, cluster_names, k)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "report_pprint(df, clusters, terms, cluster_centers_, num_clusters, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## latent dirichlet allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = list(map(lambda x: sorted(x, key=lambda e: e[1], reverse=True)[0][0], lda[corpus]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = list(set([e[0] for c in topics_matrix for e in c[1]]))\n",
    "values = [{e[0]:e[1] for e in c[1]} for c in topics_matrix]\n",
    "cluster_centers_ = np.array([[values[i].get(k,0.) for k in terms] for i in range(len(values))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['没有,什么,都,了,一次,一定,刘备,武将,一个,就',\n",
       " '啊,了,太,核心,平衡,逼,点,影响,操作,失望',\n",
       " '开始,的,从,了,玩法,韭菜,以后,东西,评分,一',\n",
       " ' ,了,的,我,都,就,然后,还,网易,是',\n",
       " '要,肝,又,时间,抽卡,在,恶心,花,但是,你',\n",
       " '赛季,征服,到,了,大,的,用,一个,也,越来越',\n",
       " '—,�,把玩,家当,开服,:,哪个,分割线,奥,计算',\n",
       " '队伍,一点,这次,的,时,了,劝退,长,不好,有',\n",
       " '不,知道,了,也,充钱,可能,都,不想,对,我',\n",
       " '我,让,的,希望,是,了,你,别,才,下来']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_names = get_cluster_names(k, cluster_centers_, terms)\n",
    "cluster_names"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "report(df, clusters, terms, cluster_centers_, num_clusters, xs, ys, cluster_names, k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
